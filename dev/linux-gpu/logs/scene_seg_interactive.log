Capturing execution frames: scene_seg_interactive.json
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
  [Console-warning] [ComfyUI Notice] "extensions/core/widgetInputs.js" is an internal module, not part of the public API. Future updates may break this import.
  [Console-warning] [ComfyUI Notice] "scripts/utils.js" is an internal module, not part of the public API. Future updates may break this import.
  [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui.js" is deprecated and will be removed in v1.34.
  [Console-warning] [ComfyUI Notice] "scripts/widgets.js" is an internal module, not part of the public API. Future updates may break this import.
  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
  [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/buttonGroup.js" is deprecated and will be removed in v1.34.
  [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/button.js" is deprecated and will be removed in v1.34.
  Frame 1 saved (frame_000.jpg, t=0.0s)
  Validating workflow...
  [ComfyUI] === /validate endpoint called ===
  [ComfyUI] Received JSON with keys: ['prompt']
  [ComfyUI] Prompt has 4 nodes
  [ComfyUI]   Node 1: LoadImage
  [ComfyUI]     Inputs: {"image": "image.png"}
  [ComfyUI]   Node 4: MaskPreview
  [ComfyUI]     Inputs: {"mask": ["25", 0]}
  [ComfyUI]   Node 12: LoadSAM3Model
  [ComfyUI]     Inputs: {"precision": "auto", "attention": "auto", "compile": false}
  [ComfyUI]   Node 25: SAM3InteractiveCollector
  [ComfyUI]     Inputs: {"multi_prompts_store": "[{\"positive_points\":[{\"x\":3346.704486138097,\"y\":2681.6412520604563},{\"x\":3353.9719078740486,\"y\":2332.7978245699082}],\"negative_points\":[],\"positive_boxes\":[],\"n
  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2
  [ComfyUI] Calling execution.validate_prompt()...
  [ComfyUI] Validation result: valid=True
  [ComfyUI] === Validation PASSED ===
  Queuing workflow for execution...
  [ComfyUI] got prompt
  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'
  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
  [ComfyUI] Sam3VideoPredictor using device: cuda:0
  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.
  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16
  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor
  Frame 2 saved (frame_001.jpg, t=3.0s)
  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True
  [ComfyUI] Model ready (1756.7 MB)
  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity
  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0
  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16
  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]
  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]
  Frame 3 saved (frame_002.jpg, t=5.3s)
  [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True
  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]
  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]
  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']
  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539
  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375
  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625
  [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13
  Frame 4 saved (frame_003.jpg, t=7.8s)
  [capture-periodic] freeze=5ms shot=153ms unfreeze=162ms saved=True
  Frame 5 saved (frame_004.jpg, t=10.2s)
  [capture-periodic] freeze=3ms shot=151ms unfreeze=8ms saved=True
  Node executed (1 total), capturing...
  [ComfyUI] Prompt executed in 12.99 seconds
  Frame 6 saved (frame_005.jpg, t=13.8s)
  [capture-node] freeze=5ms shot=190ms unfreeze=19ms saved=True
  Node executed (2 total), capturing...
  Frame 7 saved (frame_006.jpg, t=14.3s)
  [capture-node] freeze=224ms shot=1140ms unfreeze=7ms saved=True
  Execution complete (t=16.0s)
  Captured 7 unique frames over 15.99s
  [debug] iframes: 0
  [timing] trigger_3d_previews: 0.0s
  Saved high-quality screenshot: scene_seg_interactive_executed.png
  [timing] final_screenshot: 1.4s
    Captured 8 video frames
    VRAM log: /home/shadeform/vramlogs/SAM3_scene_seg_interactive_20260226_010108.csv