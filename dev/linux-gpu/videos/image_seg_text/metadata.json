{
  "frames": [
    {
      "file": "frame_000.jpg",
      "time": 0.0,
      "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34."
    },
    {
      "file": "frame_001.jpg",
      "time": 2.35,
      "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor"
    },
    {
      "file": "frame_002.jpg",
      "time": 4.68,
      "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250"
    },
    {
      "file": "frame_003.jpg",
      "time": 7.01,
      "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  Frame 3 saved (frame_002.jpg, t=4.7s)\n  [capture-periodic] freeze=5ms shot=224ms unfreeze=7ms saved=True\n  [ComfyUI] Encoder.forward OUT:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] _run_encoder output:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] Decoder.forward OUT:   output=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   ref_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   presence=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _run_decoder output:   hs=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   reference_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.bfloat16 [6, 1, 200, 1] min=-6.9062 max=-1.0547\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]   obj_queries=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   semantic_seg=torch.bfloat16 [1, 1, 288, 288] min=-35.5000 max=13.5000   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.bfloat16 [1, 200, 1] min=-6.9062 max=-1.1406   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] [DEBUG] forward_grounding output keys: ['encoder_hidden_states', 'prev_encoder_out', 'presence_feats', 'queries', 'presence_logit_dec', 'pred_logits', 'pred_boxes', 'pred_boxes_xyxy', 'pred_masks', 'semantic_seg', 'presence_logit']\n  [ComfyUI] [DEBUG] pred_logits shape: torch.Size([1, 200, 1]), min: -6.9062, max: -1.1406\n  [ComfyUI] [DEBUG] pred_boxes shape: torch.Size([1, 200, 4])\n  [ComfyUI] [DEBUG] pred_masks shape: torch.Size([1, 200, 288, 288])\n  [ComfyUI] [DEBUG] presence_logit_dec: torch.Size([1, 1]), val=[-1.0546875], sigmoid=[0.2578125]\n  [ComfyUI] [DEBUG] out_probs (joint_box_scores, no double presence): min=0.0010, max=0.2422\n  [ComfyUI] [DEBUG] confidence_threshold: 0.2\n  [ComfyUI] [DEBUG] detections above threshold: 6 / 200\n  [ComfyUI] [DEBUG] top-10 probs: ['0.2422', '0.2383', '0.2363', '0.2354', '0.2354', '0.2295', '0.0233', '0.0192', '0.0188', '0.0186']\n  [ComfyUI] [DEBUG] after threshold: 6 detections\n  [ComfyUI] [DEBUG] after NMS (iou_thresh=0.5): 6 detections (suppressed 0)\n  [ComfyUI] Found 6 detections above threshold 0.2\n  [ComfyUI] Sorting 6 detections by score...\n  [ComfyUI] Creating visualization...\n  [ComfyUI] Detection complete: 6 masks"
    },
    {
      "file": "frame_004.jpg",
      "time": 7.77,
      "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  Frame 3 saved (frame_002.jpg, t=4.7s)\n  [capture-periodic] freeze=5ms shot=224ms unfreeze=7ms saved=True\n  [ComfyUI] Encoder.forward OUT:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] _run_encoder output:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] Decoder.forward OUT:   output=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   ref_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   presence=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _run_decoder output:   hs=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   reference_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.bfloat16 [6, 1, 200, 1] min=-6.9062 max=-1.0547\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]   obj_queries=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   semantic_seg=torch.bfloat16 [1, 1, 288, 288] min=-35.5000 max=13.5000   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.bfloat16 [1, 200, 1] min=-6.9062 max=-1.1406   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] [DEBUG] forward_grounding output keys: ['encoder_hidden_states', 'prev_encoder_out', 'presence_feats', 'queries', 'presence_logit_dec', 'pred_logits', 'pred_boxes', 'pred_boxes_xyxy', 'pred_masks', 'semantic_seg', 'presence_logit']\n  [ComfyUI] [DEBUG] pred_logits shape: torch.Size([1, 200, 1]), min: -6.9062, max: -1.1406\n  [ComfyUI] [DEBUG] pred_boxes shape: torch.Size([1, 200, 4])\n  [ComfyUI] [DEBUG] pred_masks shape: torch.Size([1, 200, 288, 288])\n  [ComfyUI] [DEBUG] presence_logit_dec: torch.Size([1, 1]), val=[-1.0546875], sigmoid=[0.2578125]\n  [ComfyUI] [DEBUG] out_probs (joint_box_scores, no double presence): min=0.0010, max=0.2422\n  [ComfyUI] [DEBUG] confidence_threshold: 0.2\n  [ComfyUI] [DEBUG] detections above threshold: 6 / 200\n  [ComfyUI] [DEBUG] top-10 probs: ['0.2422', '0.2383', '0.2363', '0.2354', '0.2354', '0.2295', '0.0233', '0.0192', '0.0188', '0.0186']\n  [ComfyUI] [DEBUG] after threshold: 6 detections\n  [ComfyUI] [DEBUG] after NMS (iou_thresh=0.5): 6 detections (suppressed 0)\n  [ComfyUI] Found 6 detections above threshold 0.2\n  [ComfyUI] Sorting 6 detections by score...\n  [ComfyUI] Creating visualization...\n  [ComfyUI] Detection complete: 6 masks\n  [capture-loop] iter=50 t=7.0s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=7\n  [ComfyUI] Prompt executed in 6.90 seconds\n  Frame 4 saved (frame_003.jpg, t=7.0s)\n  [capture-periodic] freeze=23ms shot=191ms unfreeze=5ms saved=True"
    },
    {
      "file": "frame_005.jpg",
      "time": 11.82822871208191,
      "log": "Final screenshot"
    }
  ],
  "total_time": 8.26
}