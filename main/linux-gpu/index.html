<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ComfyUI-SAM3 - Test Results</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0f1923;
            color: #e6edf3;
            min-height: 100vh;
            line-height: 1.6;
        }

        header {
            background: #162033;
            padding: 1.25rem 2rem;
            border-bottom: 1px solid #243656;
        }

        body.in-iframe header {
            display: none;
        }

        body.in-iframe .container {
            padding-top: 1.25rem;
        }

        body.in-iframe .summary-meta {
            display: flex;
            gap: 0.5rem;
            flex-wrap: wrap;
            margin-bottom: 1rem;
        }

        h1 {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        h1 a {
            color: #e6edf3;
            text-decoration: none;
        }

        h1 a:hover { color: #58a6ff; }

        .meta-chips {
            display: flex;
            gap: 0.5rem;
            flex-wrap: wrap;
            align-items: center;
        }

        .meta-chip {
            display: inline-flex;
            align-items: center;
            gap: 0.35rem;
            padding: 0.2rem 0.6rem;
            background: #1c2d44;
            border: 1px solid #243656;
            border-radius: 2rem;
            font-size: 0.75rem;
            color: #8ba3c1;
        }

        .meta-chip svg {
            width: 12px;
            height: 12px;
            fill: currentColor;
            flex-shrink: 0;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
        }

        /* Summary Section */
        .summary {
            background: #162033;
            border: 1px solid #243656;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 2rem;
        }

        .progress-wrapper {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-bottom: 1rem;
        }

        .progress-bar {
            background: #1c2d44;
            border-radius: 6px;
            height: 10px;
            overflow: hidden;
            flex: 1;
        }

        .progress-fill {
            background: #3fb950;
            height: 100%;
            border-radius: 6px;
            transition: width 0.3s ease;
        }

        .progress-fill.has-failures {
            background: linear-gradient(90deg, #3fb950 0%, #3fb950 100.0%, #f85149 100.0%, #f85149 100%);
            width: 100% !important;
            border-radius: 6px;
        }

        .progress-label {
            font-size: 0.85rem;
            font-weight: 600;
            color: #8ba3c1;
            white-space: nowrap;
            min-width: 3.5rem;
            text-align: right;
        }

        .stats {
            display: flex;
            gap: 0.75rem;
            flex-wrap: wrap;
            align-items: center;
        }

        .stat-badge {
            padding: 0.35rem 0.75rem;
            border-radius: 2rem;
            font-weight: 600;
            font-size: 0.8rem;
        }

        .stat-pass {
            background: rgba(63, 185, 80, 0.15);
            color: #3fb950;
        }

        .stat-fail {
            background: rgba(248, 81, 73, 0.15);
            color: #f85149;
        }

        .stat-total {
            color: #8ba3c1;
            font-size: 0.85rem;
        }

        /* Failed Section */
        .failed-section {
            background: rgba(248, 81, 73, 0.08);
            border: 1px solid rgba(248, 81, 73, 0.3);
            border-radius: 8px;
            padding: 1.25rem;
            margin-bottom: 2rem;
        }

        .failed-section h2 {
            color: #f85149;
            font-size: 0.9rem;
            font-weight: 600;
            margin-bottom: 0.75rem;
        }

        .failed-item {
            background: #162033;
            border: 1px solid #243656;
            border-radius: 6px;
            padding: 1rem;
            margin-bottom: 0.5rem;
        }

        .failed-item:last-child {
            margin-bottom: 0;
        }

        .failed-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
        }

        .failed-name {
            font-weight: 600;
            color: #f85149;
        }

        .failed-duration {
            color: #8ba3c1;
            font-size: 0.8rem;
        }

        .failed-error {
            background: #0f1923;
            border: 1px solid #243656;
            padding: 0.75rem;
            border-radius: 6px;
            font-family: 'SFMono-Regular', 'Menlo', 'Monaco', monospace;
            font-size: 0.8rem;
            color: #d29922;
            margin-bottom: 0.5rem;
        }

        .log-link {
            color: #58a6ff;
            text-decoration: none;
            font-size: 0.8rem;
        }

        .log-link:hover {
            text-decoration: underline;
        }

        /* Workflow Grid */
        .section-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1.25rem;
        }

        .section-title {
            font-size: 0.8rem;
            color: #8ba3c1;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.06em;
        }

        .view-controls {
            display: flex;
            gap: 0;
            align-items: center;
            border: 1px solid #243656;
            border-radius: 6px;
            overflow: hidden;
        }

        .view-btn {
            background: #1c2d44;
            color: #8ba3c1;
            border: none;
            border-right: 1px solid #243656;
            padding: 0.3rem 0.75rem;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 500;
            transition: all 0.15s;
        }

        .view-btn:last-child {
            border-right: none;
        }

        .view-btn:hover {
            background: #243656;
            color: #e6edf3;
        }

        .view-btn.active {
            background: #58a6ff;
            color: #fff;
        }

        .workflow-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 1rem;
        }

        .workflow-grid.view-list {
            grid-template-columns: 1fr;
            gap: 0;
        }

        .workflow-grid.view-list .workflow-card {
            border-radius: 0;
            border-bottom: 1px solid #243656;
        }

        .workflow-grid.view-list .workflow-card:first-child {
            border-radius: 8px 8px 0 0;
        }

        .workflow-grid.view-list .workflow-card:last-child {
            border-radius: 0 0 8px 8px;
            border-bottom: none;
        }

        .workflow-grid.view-list .workflow-card:only-child {
            border-radius: 8px;
        }

        .workflow-grid.view-list .workflow-screenshot {
            width: 100%;
            height: auto;
            aspect-ratio: auto;
        }

        .workflow-grid.view-list .workflow-info {
            border-top: 1px solid #243656;
            padding: 0.75rem 1rem;
        }

        .workflow-grid.view-list .workflow-name {
            max-width: none;
            font-size: 0.9rem;
        }

        .workflow-card {
            background: #162033;
            border: 1px solid #243656;
            border-radius: 8px;
            overflow: hidden;
            transition: transform 0.15s, border-color 0.15s;
        }

        .workflow-card:hover {
            transform: translateY(-1px);
            border-color: #4a6282;
        }

        .workflow-card.clickable {
            cursor: pointer;
        }

        .workflow-card.failed {
            border-color: #f85149;
        }

        .workflow-card.failed:hover {
            border-color: #f85149;
        }

        .workflow-screenshot {
            width: 100%;
            aspect-ratio: 16/10;
            object-fit: cover;
            background: #0f1923;
            display: block;
        }

        .workflow-screenshot.placeholder {
            display: flex;
            align-items: center;
            justify-content: center;
            color: #4a6282;
            font-size: 0.8rem;
        }

        .workflow-info {
            padding: 0.75rem 1rem;
            border-top: 1px solid #243656;
        }

        .workflow-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 0.25rem;
        }

        .workflow-name {
            font-weight: 500;
            font-size: 0.85rem;
            color: #e6edf3;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            max-width: 65%;
        }

        .workflow-badge {
            padding: 0.15rem 0.5rem;
            border-radius: 2rem;
            font-size: 0.7rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.03em;
            flex-shrink: 0;
        }

        .workflow-badge.pass {
            background: rgba(63, 185, 80, 0.15);
            color: #3fb950;
        }

        .workflow-badge.fail {
            background: rgba(248, 81, 73, 0.15);
            color: #f85149;
        }

        .workflow-meta {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.75rem;
            color: #4a6282;
        }

        /* Lightbox */
        .lightbox {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(1, 4, 9, 0.9);
            z-index: 1000;
            justify-content: center;
            align-items: flex-start;
            padding: 2rem;
            overflow-y: auto;
        }

        .lightbox.active {
            display: flex;
        }

        .lightbox-content {
            display: flex;
            flex-direction: column;
            max-width: 1200px;
            width: 100%;
            margin: auto;
        }

        .lightbox-content img {
            max-width: 100%;
            max-height: 60vh;
            object-fit: contain;
            border-radius: 8px;
            border: 1px solid #243656;
            align-self: center;
        }

        .lightbox-close {
            position: fixed;
            top: 1rem;
            right: 1.5rem;
            font-size: 2rem;
            color: #e6edf3;
            cursor: pointer;
            opacity: 0.6;
            background: none;
            border: none;
            z-index: 1001;
        }

        .lightbox-close:hover {
            opacity: 1;
        }

        .lightbox-info {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: #162033;
            border: 1px solid #243656;
            border-radius: 8px;
            margin-top: 1rem;
        }

        .lightbox-title {
            font-size: 1rem;
            font-weight: 600;
            color: #e6edf3;
        }

        .lightbox-hardware {
            display: block;
            font-size: 0.75rem;
            color: #8ba3c1;
            margin-top: 0.25rem;
        }

        .lightbox-meta {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        .lightbox-badge {
            padding: 0.25rem 0.75rem;
            border-radius: 2rem;
            font-size: 0.8rem;
            font-weight: 600;
            text-transform: uppercase;
        }

        .lightbox-badge.pass {
            background: rgba(63, 185, 80, 0.15);
            color: #3fb950;
        }

        .lightbox-badge.fail {
            background: rgba(248, 81, 73, 0.15);
            color: #f85149;
        }

        .lightbox-duration {
            color: #8ba3c1;
            font-size: 0.85rem;
        }

        .lightbox-log {
            background: #0f1923;
            border: 1px solid #243656;
            border-radius: 8px;
            padding: 1rem;
            margin-top: 1rem;
            max-height: 300px;
            overflow-y: auto;
            font-family: 'SFMono-Regular', 'Menlo', 'Monaco', monospace;
            font-size: 0.8rem;
            line-height: 1.5;
            white-space: pre-wrap;
            word-break: break-all;
            color: #8ba3c1;
        }

        .lightbox-log::-webkit-scrollbar {
            width: 8px;
        }

        .lightbox-log::-webkit-scrollbar-track {
            background: #162033;
            border-radius: 4px;
        }

        .lightbox-log::-webkit-scrollbar-thumb {
            background: #243656;
            border-radius: 4px;
        }

        .lightbox-log::-webkit-scrollbar-thumb:hover {
            background: #4a6282;
        }

        /* Resource Graph */
        .resource-graph {
            display: none;
            margin-top: 1rem;
            background: #162033;
            border: 1px solid #243656;
            border-radius: 8px;
            padding: 1rem;
        }

        .resource-graph.active {
            display: block;
        }

        .resource-graph-title {
            font-size: 0.8rem;
            color: #8ba3c1;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }

        .resource-graph canvas {
            width: 100%;
            height: 120px;
            cursor: crosshair;
        }

        .resource-legend {
            display: flex;
            gap: 1rem;
            margin-top: 0.5rem;
            font-size: 0.75rem;
            color: #8ba3c1;
        }

        .resource-legend span {
            display: flex;
            align-items: center;
            gap: 4px;
        }

        .resource-legend .dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
        }

        .resource-legend .ram { background: #3fb950; }
        .resource-legend .gpu { background: #d29922; }

        /* Video Player */
        .video-player {
            display: none;
            margin-top: 1rem;
            background: #162033;
            border: 1px solid #243656;
            border-radius: 8px;
            padding: 1rem;
        }

        .video-player.active {
            display: block;
        }

        .video-controls {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-top: 0.5rem;
        }

        .video-play-btn {
            background: #58a6ff;
            color: #fff;
            border: none;
            padding: 0.4rem 1rem;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.8rem;
            font-weight: 500;
        }

        .video-play-btn:hover {
            background: #79b8ff;
        }

        .video-frame-counter {
            color: #8ba3c1;
            font-size: 0.8rem;
        }

        .video-slider-container {
            padding: 15px 0;
        }

        /* noUiSlider customization */
        #video-slider {
            height: 6px;
            background: #1c2d44;
            border: none;
            box-shadow: none;
        }

        #video-slider .noUi-connect {
            background: #58a6ff;
        }

        #video-slider .noUi-handle {
            width: 16px;
            height: 16px;
            background: #58a6ff;
            border: none;
            border-radius: 50%;
            box-shadow: none;
            top: -5px;
            right: -8px;
            cursor: pointer;
        }

        #video-slider .noUi-handle:before,
        #video-slider .noUi-handle:after {
            display: none;
        }

        /* Pips (tick marks) */
        .noUi-pips {
            color: #4a6282;
        }

        .noUi-marker {
            background: #243656;
            width: 2px;
        }

        .noUi-marker-large {
            height: 12px;
        }

        .noUi-value {
            display: none;
        }

        /* Models Section */
        .models-section {
            margin-top: 2rem;
            margin-bottom: 2rem;
        }

        .models-total {
            font-size: 0.8rem;
            color: #8ba3c1;
        }

        .models-folder {
            background: #162033;
            border: 1px solid #243656;
            border-radius: 8px;
            margin-bottom: 0.5rem;
            overflow: hidden;
        }

        .models-folder-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1rem;
            cursor: pointer;
            user-select: none;
            list-style: none;
        }

        .models-folder-header::-webkit-details-marker {
            display: none;
        }

        .models-folder-header::before {
            content: '\25B6';
            font-size: 0.6rem;
            color: #4a6282;
            margin-right: 0.5rem;
            transition: transform 0.15s;
        }

        .models-folder[open] > .models-folder-header::before {
            transform: rotate(90deg);
        }

        .models-folder-name {
            font-family: 'SFMono-Regular', 'Menlo', 'Monaco', monospace;
            font-size: 0.85rem;
            font-weight: 600;
            color: #58a6ff;
        }

        .models-folder-meta {
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }

        .models-folder-size {
            font-size: 0.8rem;
            font-weight: 600;
            color: #8ba3c1;
        }

        .models-source-link {
            font-size: 0.75rem;
            color: #3fb950;
            text-decoration: none;
            padding: 0.15rem 0.5rem;
            background: rgba(63, 185, 80, 0.1);
            border: 1px solid rgba(63, 185, 80, 0.2);
            border-radius: 2rem;
        }

        .models-source-link:hover {
            background: rgba(63, 185, 80, 0.2);
            text-decoration: none;
        }

        .models-file-list {
            border-top: 1px solid #243656;
            padding: 0.25rem 0;
        }

        .models-file {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.35rem 1rem 0.35rem 2rem;
            font-size: 0.8rem;
        }

        .models-file:hover {
            background: rgba(88, 166, 255, 0.05);
        }

        .models-file-path {
            font-family: 'SFMono-Regular', 'Menlo', 'Monaco', monospace;
            color: #8ba3c1;
            word-break: break-all;
        }

        .models-file-size {
            color: #4a6282;
            white-space: nowrap;
            margin-left: 1rem;
            flex-shrink: 0;
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 2.5rem;
            color: #4a6282;
            font-size: 0.8rem;
        }

        footer a {
            color: #58a6ff;
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }

        /* Responsive */
        @media (max-width: 600px) {
            .workflow-grid {
                grid-template-columns: 1fr !important;
            }

            .workflow-grid.view-list .workflow-card {
                grid-template-columns: 1fr;
            }

            .workflow-grid.view-list .workflow-screenshot {
                width: 100%;
                height: auto;
                aspect-ratio: 16/10;
            }

            .stats {
                flex-direction: column;
                align-items: flex-start;
            }

            .section-header {
                flex-direction: column;
                align-items: flex-start;
                gap: 0.5rem;
            }

            .container {
                padding: 1rem;
            }
        }
    </style>
    <link href="https://cdn.jsdelivr.net/npm/nouislider@15/dist/nouislider.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/nouislider@15/dist/nouislider.min.js"></script>
</head>
<body>
    <header>
        <h1><a href="https://github.com/PozzettiAndrea/ComfyUI-SAM3">ComfyUI-SAM3</a> Test Results</h1>
        <div class="meta-chips">
            <span class="meta-chip"><svg viewBox="0 0 16 16"><path d="M8 0a8 8 0 110 16A8 8 0 018 0zm.5 4.5a.5.5 0 00-1 0v3.793L5.854 9.854a.5.5 0 10.708.708l1.853-1.854a.5.5 0 00.085-.094V4.5z"/></svg> 2026-02-26 01:02 UTC</span> <span class="meta-chip"><svg viewBox="0 0 16 16"><path d="M2.5 4a.5.5 0 100 1 .5.5 0 000-1zM4 4.5a.5.5 0 01.5-.5h7a.5.5 0 010 1h-7a.5.5 0 01-.5-.5zM2.5 7a.5.5 0 100 1 .5.5 0 000-1zM4 7.5a.5.5 0 01.5-.5h7a.5.5 0 010 1h-7A.5.5 0 014 7.5zM2.5 10a.5.5 0 100 1 .5.5 0 000-1zM4 10.5a.5.5 0 01.5-.5h7a.5.5 0 010 1h-7a.5.5 0 01-.5-.5z"/></svg> Linux-6.8.0-90-generic-x86_64-with-glibc2.35</span> <span class="meta-chip"><svg viewBox="0 0 16 16"><path d="M5 0a.5.5 0 01.5.5V2h1V.5a.5.5 0 011 0V2h1V.5a.5.5 0 011 0V2h.5A2.5 2.5 0 0112.5 4.5H14v1h-1.5v1H14v1h-1.5v1H14v1h-1.5A2.5 2.5 0 0110 12h-.5v1.5a.5.5 0 01-1 0V12h-1v1.5a.5.5 0 01-1 0V12H6v1.5a.5.5 0 01-1 0V12h-.5A2.5 2.5 0 012 9.5H.5v-1H2v-1H.5v-1H2v-1H.5v-1H2A2.5 2.5 0 014.5 2V.5A.5.5 0 015 0zm-.5 4A1.5 1.5 0 003 5.5v4A1.5 1.5 0 004.5 11h6a1.5 1.5 0 001.5-1.5v-4A1.5 1.5 0 0010.5 4h-6z"/></svg> Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz</span> <span class="meta-chip"><svg viewBox="0 0 16 16"><path d="M4 8a1.5 1.5 0 113 0 1.5 1.5 0 01-3 0zm7.5-1.5a1.5 1.5 0 100 3 1.5 1.5 0 000-3zM3 2a2 2 0 00-2 2v8a2 2 0 002 2h10a2 2 0 002-2V4a2 2 0 00-2-2H3z"/></svg> NVIDIA RTX A6000</span>
        </div>
    </header>

    <div class="container">
        <div class="summary">
            <div class="progress-wrapper">
                <div class="progress-bar">
                    <div class="progress-fill" style="width: 100.0%"></div>
                </div>
                <span class="progress-label">100.0%</span>
            </div>
            <div class="stats">
                <span class="stat-badge stat-pass">5 passed</span>
                
                <span class="stat-total">5/5 tests</span>
            </div>
        </div>

        <div class="section-header">
            <h2 class="section-title">Workflows</h2>
            <div class="view-controls">
                <button class="view-btn active" onclick="setView('grid')">Grid</button>
                <button class="view-btn" onclick="setView('list')">List</button>
            </div>
        </div>
        <div class="workflow-grid" id="workflow-grid">
            
            <div class="workflow-card clickable " onclick="openLightboxByName('image_seg_point')">
                
                <img class="workflow-screenshot" src="screenshots/image_seg_point_executed.png"
                     alt="image_seg_point" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="image_seg_point">image_seg_point</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>53.22s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('image_seg_text')">
                
                <img class="workflow-screenshot" src="screenshots/image_seg_text_executed.png"
                     alt="image_seg_text" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="image_seg_text">image_seg_text</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>19.80s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('scene_seg')">
                
                <img class="workflow-screenshot" src="screenshots/scene_seg_executed.png"
                     alt="scene_seg" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="scene_seg">scene_seg</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>64.99s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('scene_seg_interactive')">
                
                <img class="workflow-screenshot" src="screenshots/scene_seg_interactive_executed.png"
                     alt="scene_seg_interactive" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="scene_seg_interactive">scene_seg_interactive</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>28.37s</span>
                    </div>
                </div>
            </div>
        

            <div class="workflow-card clickable " onclick="openLightboxByName('video_point_prompt')">
                
                <img class="workflow-screenshot" src="screenshots/video_point_prompt_executed.png"
                     alt="video_point_prompt" loading="lazy">
            
                <div class="workflow-info">
                    <div class="workflow-header">
                        <span class="workflow-name" title="video_point_prompt">video_point_prompt</span>
                        <span class="workflow-badge pass">pass</span>
                    </div>
                    <div class="workflow-meta">
                        <span>53.37s</span>
                    </div>
                </div>
            </div>
        
        </div>

        

        
        <div class="models-section">
            <div class="section-header">
                <h2 class="section-title">Downloaded Models</h2>
                <span class="models-total">3 files &middot; 3.2 GB</span>
            </div>
            
            <details class="models-folder" open>
                <summary class="models-folder-header">
                    <span class="models-folder-name">models/sam3/</span>
                    <span class="models-folder-meta">
                        
                        <span class="models-folder-size">3.2 GB</span>
                    </span>
                </summary>
                <div class="models-file-list">
                    <div class="models-file"><span class="models-file-path">sam3.safetensors</span><span class="models-file-size">3.2 GB</span></div>
<div class="models-file"><span class="models-file-path">.cache/huggingface/download/sam3.safetensors.metadata</span><span class="models-file-size">125.0 B</span></div>
<div class="models-file"><span class="models-file-path">.cache/huggingface/.gitignore</span><span class="models-file-size">1.0 B</span></div>
                </div>
            </details>
        
        </div>
    
    </div>

    <div class="lightbox" id="lightbox">
        <button class="lightbox-close" onclick="closeLightbox()">&times;</button>
        <div class="lightbox-content">
            <img id="lightbox-img" src="" alt="">
            <div class="video-player" id="video-player">
                <div class="video-slider-container">
                    <div id="video-slider"></div>
                </div>
                <div class="video-controls">
                    <span class="video-frame-counter" id="video-frame-counter">0.0s / 0.0s</span>
                </div>
            </div>
            <div class="resource-graph" id="resource-graph">
                <div class="resource-graph-title">Resource Usage</div>
                <canvas id="resource-canvas"></canvas>
                <div class="resource-legend">
                    <span><span class="dot ram"></span> RAM (GB)</span>
                    <span id="gpu-legend" style="display:none"><span class="dot gpu"></span> VRAM (GB)</span>
                </div>
            </div>
            <div class="lightbox-info">
                <div>
                    <span class="lightbox-title" id="lightbox-title"></span>
                    <span class="lightbox-hardware" id="lightbox-hardware"></span>
                </div>
                <div class="lightbox-meta">
                    <span class="lightbox-badge" id="lightbox-badge"></span>
                    <span class="lightbox-duration" id="lightbox-duration"></span>
                </div>
            </div>
            <pre class="lightbox-log" id="lightbox-log"></pre>
        </div>
    </div>

    <footer>
        Generated by <a href="https://github.com/PozzettiAndrea/comfy-test">comfy-test</a>
    </footer>

    <script>
        function setView(mode) {
            const grid = document.getElementById('workflow-grid');
            grid.className = mode === 'list' ? 'workflow-grid view-list' : 'workflow-grid';
            document.querySelectorAll('.view-controls .view-btn').forEach(btn => {
                btn.classList.toggle('active', btn.textContent.trim().toLowerCase() === mode);
            });
        }

        const workflowData = {"image_seg_point": {"src": "screenshots/image_seg_point_executed.png", "title": "image_seg_point", "status": "pass", "duration": "53.22", "log": "Capturing execution frames: image_seg_point.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 6 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 15: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":426.27735719657574,\\\"y\\\":321.42611685978835},{\\\"x\\\":417.13743597288953,\\\"y\\\":407.3413796907987},{\\\"x\\\":431.76130993078743,\\\"y\\\":549.9241563039649}],\\\"negative\\\"\n  [ComfyUI]   Node 24: SAM3Segmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 4, \"use_multimask\": false, \"output_best_mask\": false, \"sam3_model\": [\"30\", 0], \"image\": [\"1\", 0], \"positive_points\": [\"15\", 0]}\n  [ComfyUI]   Node 28: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"24\", 2]}\n  [ComfyUI]   Node 29: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"24\", 0]}\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI] Generated prompt_id: 3ea68f8c-ab02-4a8d-b790-94ae457651b8\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d9204c29\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 1280x720\n  [ComfyUI]   Positive point: (426.3, 321.4) -> (0.333, 0.446)\n  [ComfyUI]   Positive point: (417.1, 407.3) -> (0.326, 0.566)\n  [ComfyUI]   Positive point: (431.8, 549.9) -> (0.337, 0.764)\n  [ComfyUI] Output: 3 positive, 0 negative\n  Node executed (1 total), capturing...\n  Frame 2 saved (frame_001.jpg, t=2.0s)\n  [capture-node] freeze=37ms shot=246ms unfreeze=7ms saved=True\n  [ComfyUI] Model not found at /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors, downloading from HuggingFace...\n  [ComfyUI] HTTP Request: HEAD https://huggingface.co/apozz/sam3-safetensors/resolve/main/sam3.safetensors \"HTTP/1.1 302 Found\"\n  [ComfyUI] HTTP Request: GET https://huggingface.co/api/models/apozz/sam3-safetensors/xet-read-token/e88da2ed02aded4006f4711ee6a9c75d5aa38d0c \"HTTP/1.1 200 OK\"\n  [capture-loop] iter=50 t=8.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=13\n  [capture-loop] iter=100 t=15.4s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=11\n  [capture-loop] iter=150 t=21.9s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=3\n  [ComfyUI] Model downloaded to: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Using click-based interactive segmentation\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 3 saved (frame_002.jpg, t=23.3s)\n  [capture-periodic] freeze=5ms shot=397ms unfreeze=7ms saved=True\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] sam2_backbone_out is available\n  [ComfyUI] Added 3 positive points\n  [ComfyUI] Points: 3\n  [ComfyUI]   Coords: [[426.27735719657574, 321.42611685978835], [417.13743597288953, 407.3413796907987], [431.76130993078743, 549.9241563039649]]\n  [ComfyUI]   Labels: [1, 1, 1]\n  [ComfyUI] Refinement 1/4, best score: 0.9648\n  [ComfyUI] Refinement 2/4, best score: 0.9688\n  [ComfyUI] Refinement 3/4, best score: 0.9688\n  [ComfyUI] Refinement 4/4, best score: 0.9688\n  [ComfyUI] Prediction returned 1 masks\n  [ComfyUI]   Mask shape: (1, 720, 1280)\n  [ComfyUI]   Low-res shape: (1, 288, 288)\n  [ComfyUI]   Scores: [0.96875]\n  Node executed (3 total), capturing...\n  [ComfyUI] Outputting all 1 mask candidates\n  [ComfyUI] Segmentation complete\n  [ComfyUI] Prompt executed in 25.65 seconds\n  Frame 4 saved (frame_003.jpg, t=38.6s)\n  [capture-node] freeze=10ms shot=258ms unfreeze=0ms saved=True\n  Execution complete (t=38.6s)\n  Captured 4 unique frames over 39.11s\n  [debug] iframes: 0\n  [timing] trigger_3d_previews: 0.0s\n  Saved high-quality screenshot: image_seg_point_executed.png\n  [timing] final_screenshot: 1.9s\n    Captured 5 video frames\n    VRAM log: /home/shadeform/vramlogs/SAM3_image_seg_point_20260226_005849.csv", "hardware": {"os": "Linux-6.8.0-90-generic-x86_64-with-glibc2.35", "cpu": "Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz", "gpu": "NVIDIA RTX A6000"}}, "image_seg_text": {"src": "screenshots/image_seg_text_executed.png", "title": "image_seg_text", "status": "pass", "duration": "19.80", "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  Frame 3 saved (frame_002.jpg, t=4.7s)\n  [capture-periodic] freeze=5ms shot=224ms unfreeze=7ms saved=True\n  [ComfyUI] Encoder.forward OUT:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] _run_encoder output:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] Decoder.forward OUT:   output=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   ref_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   presence=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _run_decoder output:   hs=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   reference_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.bfloat16 [6, 1, 200, 1] min=-6.9062 max=-1.0547\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]   obj_queries=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   semantic_seg=torch.bfloat16 [1, 1, 288, 288] min=-35.5000 max=13.5000   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.bfloat16 [1, 200, 1] min=-6.9062 max=-1.1406   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] [DEBUG] forward_grounding output keys: ['encoder_hidden_states', 'prev_encoder_out', 'presence_feats', 'queries', 'presence_logit_dec', 'pred_logits', 'pred_boxes', 'pred_boxes_xyxy', 'pred_masks', 'semantic_seg', 'presence_logit']\n  [ComfyUI] [DEBUG] pred_logits shape: torch.Size([1, 200, 1]), min: -6.9062, max: -1.1406\n  [ComfyUI] [DEBUG] pred_boxes shape: torch.Size([1, 200, 4])\n  [ComfyUI] [DEBUG] pred_masks shape: torch.Size([1, 200, 288, 288])\n  [ComfyUI] [DEBUG] presence_logit_dec: torch.Size([1, 1]), val=[-1.0546875], sigmoid=[0.2578125]\n  [ComfyUI] [DEBUG] out_probs (joint_box_scores, no double presence): min=0.0010, max=0.2422\n  [ComfyUI] [DEBUG] confidence_threshold: 0.2\n  [ComfyUI] [DEBUG] detections above threshold: 6 / 200\n  [ComfyUI] [DEBUG] top-10 probs: ['0.2422', '0.2383', '0.2363', '0.2354', '0.2354', '0.2295', '0.0233', '0.0192', '0.0188', '0.0186']\n  [ComfyUI] [DEBUG] after threshold: 6 detections\n  [ComfyUI] [DEBUG] after NMS (iou_thresh=0.5): 6 detections (suppressed 0)\n  [ComfyUI] Found 6 detections above threshold 0.2\n  [ComfyUI] Sorting 6 detections by score...\n  [ComfyUI] Creating visualization...\n  [ComfyUI] Detection complete: 6 masks\n  [capture-loop] iter=50 t=7.0s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=7\n  [ComfyUI] Prompt executed in 6.90 seconds\n  Frame 4 saved (frame_003.jpg, t=7.0s)\n  [capture-periodic] freeze=23ms shot=191ms unfreeze=5ms saved=True\n  Node executed (2 total), capturing...\n  Frame 5 saved (frame_004.jpg, t=7.8s)\n  [capture-node] freeze=33ms shot=247ms unfreeze=11ms saved=True\n  Execution complete (t=8.2s)\n  Captured 5 unique frames over 8.26s\n  [debug] iframes: 0\n  [timing] trigger_3d_previews: 0.0s\n  Saved high-quality screenshot: image_seg_text_executed.png\n  [timing] final_screenshot: 1.5s\n    Captured 6 video frames\n    VRAM log: /home/shadeform/vramlogs/SAM3_image_seg_text_20260226_005943.csv", "hardware": {"os": "Linux-6.8.0-90-generic-x86_64-with-glibc2.35", "cpu": "Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz", "gpu": "NVIDIA RTX A6000"}}, "scene_seg": {"src": "screenshots/scene_seg_executed.png", "title": "scene_seg", "status": "pass", "duration": "64.99", "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Node executed (1 total), capturing...\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 3 saved (frame_002.jpg, t=7.8s)\n  [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  Frame 4 saved (frame_003.jpg, t=10.5s)\n  [ComfyUI] Image size: (6720, 4480)\n  [capture-periodic] freeze=4ms shot=204ms unfreeze=5ms saved=True\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [ComfyUI] Processing prompt region 1/7\n  [ComfyUI]   Points: 10, Box: Yes\n  [ComfyUI]   Mask score: 0.9805\n  [ComfyUI] Processing prompt region 2/7\n  [ComfyUI]   Points: 23, Box: Yes\n  [ComfyUI]   Mask score: 0.9414\n  [ComfyUI] Processing prompt region 3/7\n  [ComfyUI]   Points: 21, Box: Yes\n  [capture-loop] iter=50 t=12.1s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [ComfyUI]   Mask score: 0.9023\n  [ComfyUI] Processing prompt region 4/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9766\n  [ComfyUI] Processing prompt region 5/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9844\n  [ComfyUI] Processing prompt region 6/7\n  [ComfyUI]   Points: 13, Box: Yes\n  [ComfyUI]   Mask score: 0.9883\n  [ComfyUI] Processing prompt region 7/7\n  [ComfyUI]   Points: 6, Box: Yes\n  [ComfyUI]   Mask score: 0.9688\n  [ComfyUI] Generated 7 masks\n  [capture-loop] iter=100 t=18.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [capture-loop] iter=150 t=24.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [capture-loop] iter=200 t=31.0s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=8\n  Frame 5 saved (frame_004.jpg, t=33.3s)\n  [capture-periodic] freeze=4ms shot=212ms unfreeze=10ms saved=True\n  [capture-loop] iter=250 t=37.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Node executed (2 total), capturing...\n  Frame 6 saved (frame_005.jpg, t=38.2s)\n  [capture-node] freeze=247ms shot=1271ms unfreeze=9ms saved=True\n  [capture-loop] iter=300 t=45.6s state={'complete': False, 'error': None, 'executedCount': 2, 'wsState': 1} eval_ms=5\n  Node executed (3 total), capturing...\n  Frame 7 saved (frame_006.jpg, t=48.9s)\n  [capture-node] freeze=4ms shot=204ms unfreeze=7ms saved=True\n  Node executed (4 total), capturing...\n  Frame 8 saved (frame_007.jpg, t=50.6s)\n  [capture-node] freeze=4ms shot=243ms unfreeze=11ms saved=True\n  [ComfyUI] Prompt executed in 50.20 seconds\n  Execution complete (t=51.1s)\n  Captured 8 unique frames over 51.13s\n  [debug] iframes: 0\n  [timing] trigger_3d_previews: 0.0s\n  Saved high-quality screenshot: scene_seg_executed.png\n  [timing] final_screenshot: 2.4s\n    Captured 9 video frames\n    VRAM log: /home/shadeform/vramlogs/SAM3_scene_seg_20260226_010003.csv", "hardware": {"os": "Linux-6.8.0-90-generic-x86_64-with-glibc2.35", "cpu": "Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz", "gpu": "NVIDIA RTX A6000"}}, "scene_seg_interactive": {"src": "screenshots/scene_seg_interactive_executed.png", "title": "scene_seg_interactive", "status": "pass", "duration": "28.37", "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  Frame 3 saved (frame_002.jpg, t=5.3s)\n  [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13\n  Frame 4 saved (frame_003.jpg, t=7.8s)\n  [capture-periodic] freeze=5ms shot=153ms unfreeze=162ms saved=True\n  Frame 5 saved (frame_004.jpg, t=10.2s)\n  [capture-periodic] freeze=3ms shot=151ms unfreeze=8ms saved=True\n  Node executed (1 total), capturing...\n  [ComfyUI] Prompt executed in 12.99 seconds\n  Frame 6 saved (frame_005.jpg, t=13.8s)\n  [capture-node] freeze=5ms shot=190ms unfreeze=19ms saved=True\n  Node executed (2 total), capturing...\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-node] freeze=224ms shot=1140ms unfreeze=7ms saved=True\n  Execution complete (t=16.0s)\n  Captured 7 unique frames over 15.99s\n  [debug] iframes: 0\n  [timing] trigger_3d_previews: 0.0s\n  Saved high-quality screenshot: scene_seg_interactive_executed.png\n  [timing] final_screenshot: 1.4s\n    Captured 8 video frames\n    VRAM log: /home/shadeform/vramlogs/SAM3_scene_seg_interactive_20260226_010108.csv", "hardware": {"os": "Linux-6.8.0-90-generic-x86_64-with-glibc2.35", "cpu": "Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz", "gpu": "NVIDIA RTX A6000"}}, "video_point_prompt": {"src": "screenshots/video_point_prompt_executed.png", "title": "video_point_prompt", "status": "pass", "duration": "53.37", "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 ma\n... (truncated)", "hardware": {"os": "Linux-6.8.0-90-generic-x86_64-with-glibc2.35", "cpu": "Intel(R) Xeon(R) CPU E5-2683 v4 @ 2.10GHz", "gpu": "NVIDIA RTX A6000"}}};
        const videoData = {"video_point_prompt": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34."}, {"file": "frame_001.jpg", "time": 2.37, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo"}, {"file": "frame_002.jpg", "time": 4.76, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor"}, {"file": "frame_003.jpg", "time": 7.13, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]"}, {"file": "frame_004.jpg", "time": 9.65, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000"}, {"file": "frame_005.jpg", "time": 12.01, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000"}, {"file": "frame_006.jpg", "time": 14.31, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000"}, {"file": "frame_007.jpg", "time": 16.65, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]"}, {"file": "frame_008.jpg", "time": 18.99, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)"}, {"file": "frame_009.jpg", "time": 21.26, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882"}, {"file": "frame_010.jpg", "time": 23.67, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] "}, {"file": "frame_011.jpg", "time": 25.96, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10"}, {"file": "frame_012.jpg", "time": 28.2, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True"}, {"file": "frame_013.jpg", "time": 30.5, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True\n  Frame 13 saved (frame_012.jpg, t=28.2s)\n  [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True"}, {"file": "frame_014.jpg", "time": 32.82, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True\n  Frame 13 saved (frame_012.jpg, t=28.2s)\n  [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True\n  Frame 14 saved (frame_013.jpg, t=30.5s)\n  [capture-periodic] freeze=6ms shot=158ms unfreeze=6ms saved=True\n  [capture-loop] iter=250 t=31.7s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4"}, {"file": "frame_015.jpg", "time": 35.16, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True\n  Frame 13 saved (frame_012.jpg, t=28.2s)\n  [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True\n  Frame 14 saved (frame_013.jpg, t=30.5s)\n  [capture-periodic] freeze=6ms shot=158ms unfreeze=6ms saved=True\n  [capture-loop] iter=250 t=31.7s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Frame 15 saved (frame_014.jpg, t=32.8s)\n  [capture-periodic] freeze=3ms shot=189ms unfreeze=5ms saved=True"}, {"file": "frame_016.jpg", "time": 37.64, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True\n  Frame 13 saved (frame_012.jpg, t=28.2s)\n  [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True\n  Frame 14 saved (frame_013.jpg, t=30.5s)\n  [capture-periodic] freeze=6ms shot=158ms unfreeze=6ms saved=True\n  [capture-loop] iter=250 t=31.7s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Frame 15 saved (frame_014.jpg, t=32.8s)\n  [capture-periodic] freeze=3ms shot=189ms unfreeze=5ms saved=True\n  Frame 16 saved (frame_015.jpg, t=35.2s)\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=4ms saved=True"}, {"file": "frame_017.jpg", "time": 39.86, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True\n  Frame 13 saved (frame_012.jpg, t=28.2s)\n  [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True\n  Frame 14 saved (frame_013.jpg, t=30.5s)\n  [capture-periodic] freeze=6ms shot=158ms unfreeze=6ms saved=True\n  [capture-loop] iter=250 t=31.7s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Frame 15 saved (frame_014.jpg, t=32.8s)\n  [capture-periodic] freeze=3ms shot=189ms unfreeze=5ms saved=True\n  Frame 16 saved (frame_015.jpg, t=35.2s)\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=4ms saved=True\n  Frame 17 saved (frame_016.jpg, t=37.6s)\n  [capture-periodic] freeze=4ms shot=198ms unfreeze=5ms saved=True\n  [capture-loop] iter=300 t=38.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Output: 30 masks, shape torch.Size([30, 544, 960])\n  [ComfyUI] Objects tracked: 1, plot_all_masks: True\n  [ComfyUI] [MEM] After extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 7.12GB (process), 22.4/47.1GB (system)"}, {"file": "frame_018.jpg", "time": 40.47, "log": "Capturing execution frames: video_point_prompt.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 11 nodes\n  [ComfyUI]   Node 9: VHS_LoadVideo\n  [ComfyUI]     Inputs: {\"video\": \"bedroom.mp4\", \"force_rate\": 0, \"custom_width\": 0, \"custom_height\": 0, \"frame_load_cap\": 30, \"skip_first_frames\": 0, \"select_every_nth\": 1, \"format\": \"AnimateDiff\"}\n  [ComfyUI]   Node 13: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"14\", 0]}\n  [ComfyUI]   Node 14: MaskToImage\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 15: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"13\", 0]}\n  [ComfyUI]   Node 21: SAM3VideoOutput\n  [ComfyUI]     Inputs: {\"obj_id\": 0, \"plot_all_masks\": true, \"masks\": [\"32\", 0], \"video_state\": [\"32\", 2], \"scores\": [\"32\", 1]}\n  [ComfyUI]   Node 24: CreateVideo\n  [ComfyUI]     Inputs: {\"fps\": 30, \"images\": [\"21\", 2]}\n  [ComfyUI]   Node 25: SaveVideo\n  [ComfyUI]     Inputs: {\"filename_prefix\": \"video/ComfyUI\", \"format\": \"auto\", \"codec\": \"auto\", \"video\": [\"24\", 0]}\n  [ComfyUI]   Node 27: SAM3VideoSegmentation\n  [ComfyUI]     Inputs: {\"prompt_mode\": \"point\", \"frame_idx\": 0.3, \"score_threshold\": 0.3, \"video_frames\": [\"9\", 0], \"positive_points\": [\"28\", 0]}\n  [ComfyUI]   Node 28: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":365.8296849641195,\\\"y\\\":82.1138596932428},{\\\"x\\\":389.5481601701001,\\\"y\\\":179.95494578458334},{\\\"x\\\":413.26663537608084,\\\"y\\\":52.465045726169905}],\\\"negative\\\":[\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 32: SAM3Propagate\n  [ComfyUI]     Inputs: {\"start_frame\": 0, \"end_frame\": -1, \"direction\": \"forward\", \"sam3_model\": [\"30\", 0], \"video_state\": [\"27\", 0]}\n  [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'\n  [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None\n  [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None\n  [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d7f60d60\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 960x544\n  [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)\n  [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)\n  [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)\n  [ComfyUI] Output: 3 positive, 0 negative\n  [ComfyUI] CACHE MISS - computing new video_state for key=911ad089\n  [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo\n  Node executed (1 total), capturing...\n  [ComfyUI] Frames saved successfully\n  [ComfyUI] Initialized session e347f3b6\n  [ComfyUI] Frames: 30, Size: 960x544\n  [ComfyUI] Prompt mode: point\n  [ComfyUI] Added point prompt: obj=1, positive=3, negative=0\n  [ComfyUI] Total prompts: 1\n  [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6\n  Frame 3 saved (frame_002.jpg, t=4.8s)\n  [ComfyUI] Starting propagation: frames 0 to end\n  [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True\n  [ComfyUI] Prompts: 1\n  [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Reconstructing inference state for e347f3b6\n  [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)\n  [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True\n  [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1\n  [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Applying point prompt: frame=0, obj=1\n  [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894\n  [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered\n  [ComfyUI] Inference state for e347f3b6 garbage collected\n  [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels\n  [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels\n  [ComfyUI] \n  [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)\n  [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900\n  [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']\n  [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz\n  [ComfyUI]   Shape: (1, 10, 600, 900)\n  [ComfyUI]   Format: npz\n  [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  [ComfyUI] \n  [ComfyUI]   3%|\u2588\u2588\u2588\u2588\u258e                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876\n  Frame 4 saved (frame_003.jpg, t=7.1s)\n  [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True\n  [ComfyUI] \n  [ComfyUI]   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870\n  [ComfyUI] \n  [ComfyUI]  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  13%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865\n  [ComfyUI] \n  [ComfyUI]  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883\n  [ComfyUI] \n  Frame 5 saved (frame_004.jpg, t=9.7s)\n  [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True\n  [ComfyUI]  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901\n  [ComfyUI] \n  [ComfyUI]  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896\n  [ComfyUI] \n  [ComfyUI]  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887\n  [ComfyUI] \n  [ComfyUI]  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873\n  [ComfyUI] \n  [ComfyUI]  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 6 saved (frame_005.jpg, t=12.0s)\n  [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879\n  [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874\n  [ComfyUI] \n  [ComfyUI]  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869\n  [ComfyUI] \n  [ComfyUI]  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 7 saved (frame_006.jpg, t=14.3s)\n  [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895\n  [ComfyUI] \n  [ComfyUI]  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871\n  [ComfyUI] \n  [ComfyUI]  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866\n  [ComfyUI] \n  [ComfyUI]  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078\n  Frame 8 saved (frame_007.jpg, t=16.6s)\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847\n  [ComfyUI] \n  [ComfyUI]  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876\n  [ComfyUI] \n  [ComfyUI]  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878\n  [ComfyUI] \n  [ComfyUI]  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872\n  [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)\n  [ComfyUI] \n  [ComfyUI]  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 9 saved (frame_008.jpg, t=19.0s)\n  [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864\n  [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6\n  [ComfyUI] \n  [ComfyUI]  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883\n  [ComfyUI] \n  [ComfyUI]  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886\n  [ComfyUI] \n  [ComfyUI]  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  Frame 10 saved (frame_009.jpg, t=21.3s)\n  [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882\n  [ComfyUI] \n  [ComfyUI]  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879\n  [ComfyUI] \n  [ComfyUI]  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994\n  [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875\n  [ComfyUI] \n  [ComfyUI]  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 29/30 [00:17<00:00,  1.72it/s]\n  [ComfyUI] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:17<00:00,  1.73it/s]\n  [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)\n  [ComfyUI] Propagation complete: 30 frames processed\n  [ComfyUI] Frames with scores: 30\n  Frame 11 saved (frame_010.jpg, t=23.7s)\n  [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True\n  [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6\n  [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)\n  [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output\n  [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10\n  Frame 12 saved (frame_011.jpg, t=26.0s)\n  [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True\n  Frame 13 saved (frame_012.jpg, t=28.2s)\n  [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True\n  Frame 14 saved (frame_013.jpg, t=30.5s)\n  [capture-periodic] freeze=6ms shot=158ms unfreeze=6ms saved=True\n  [capture-loop] iter=250 t=31.7s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Frame 15 saved (frame_014.jpg, t=32.8s)\n  [capture-periodic] freeze=3ms shot=189ms unfreeze=5ms saved=True\n  Frame 16 saved (frame_015.jpg, t=35.2s)\n  [capture-periodic] freeze=3ms shot=162ms unfreeze=4ms saved=True\n  Frame 17 saved (frame_016.jpg, t=37.6s)\n  [capture-periodic] freeze=4ms shot=198ms unfreeze=5ms saved=True\n  [capture-loop] iter=300 t=38.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [ComfyUI] Output: 30 masks, shape torch.Size([30, 544, 960])\n  [ComfyUI] Objects tracked: 1, plot_all_masks: True\n  [ComfyUI] [MEM] After extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 7.12GB (process), 22.4/47.1GB (system)\n  Node executed (2 total), capturing...\n  [ComfyUI] Prompt executed in 39.94 seconds\n  Frame 18 saved (frame_017.jpg, t=39.9s)\n  [capture-node] freeze=5ms shot=253ms unfreeze=14ms saved=True"}, {"file": "frame_019.jpg", "time": 44.54176712036133, "log": "Final screenshot"}], "total_time": 40.89}, "scene_seg_interactive": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34."}, {"file": "frame_001.jpg", "time": 2.96, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead."}, {"file": "frame_002.jpg", "time": 5.35, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity"}, {"file": "frame_003.jpg", "time": 7.76, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  Frame 3 saved (frame_002.jpg, t=5.3s)\n  [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13"}, {"file": "frame_004.jpg", "time": 10.23, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  Frame 3 saved (frame_002.jpg, t=5.3s)\n  [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13\n  Frame 4 saved (frame_003.jpg, t=7.8s)\n  [capture-periodic] freeze=5ms shot=153ms unfreeze=162ms saved=True"}, {"file": "frame_005.jpg", "time": 13.79, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  Frame 3 saved (frame_002.jpg, t=5.3s)\n  [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13\n  Frame 4 saved (frame_003.jpg, t=7.8s)\n  [capture-periodic] freeze=5ms shot=153ms unfreeze=162ms saved=True\n  Frame 5 saved (frame_004.jpg, t=10.2s)\n  [capture-periodic] freeze=3ms shot=151ms unfreeze=8ms saved=True"}, {"file": "frame_006.jpg", "time": 14.34, "log": "Capturing execution frames: scene_seg_interactive.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 4 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"25\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 25: SAM3InteractiveCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":3346.704486138097,\\\"y\\\":2681.6412520604563},{\\\"x\\\":3353.9719078740486,\\\"y\\\":2332.7978245699082}],\\\"negative_points\\\":[],\\\"positive_boxes\\\":[],\\\"n\n  [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  Queuing workflow for execution...\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  Frame 3 saved (frame_002.jpg, t=5.3s)\n  [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13\n  Frame 4 saved (frame_003.jpg, t=7.8s)\n  [capture-periodic] freeze=5ms shot=153ms unfreeze=162ms saved=True\n  Frame 5 saved (frame_004.jpg, t=10.2s)\n  [capture-periodic] freeze=3ms shot=151ms unfreeze=8ms saved=True\n  Node executed (1 total), capturing...\n  [ComfyUI] Prompt executed in 12.99 seconds\n  Frame 6 saved (frame_005.jpg, t=13.8s)\n  [capture-node] freeze=5ms shot=190ms unfreeze=19ms saved=True"}, {"file": "frame_007.jpg", "time": 19.45069146156311, "log": "Final screenshot"}], "total_time": 15.99}, "image_seg_text": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34."}, {"file": "frame_001.jpg", "time": 2.35, "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor"}, {"file": "frame_002.jpg", "time": 4.68, "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250"}, {"file": "frame_003.jpg", "time": 7.01, "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  Frame 3 saved (frame_002.jpg, t=4.7s)\n  [capture-periodic] freeze=5ms shot=224ms unfreeze=7ms saved=True\n  [ComfyUI] Encoder.forward OUT:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] _run_encoder output:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] Decoder.forward OUT:   output=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   ref_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   presence=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _run_decoder output:   hs=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   reference_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.bfloat16 [6, 1, 200, 1] min=-6.9062 max=-1.0547\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]   obj_queries=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   semantic_seg=torch.bfloat16 [1, 1, 288, 288] min=-35.5000 max=13.5000   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.bfloat16 [1, 200, 1] min=-6.9062 max=-1.1406   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] [DEBUG] forward_grounding output keys: ['encoder_hidden_states', 'prev_encoder_out', 'presence_feats', 'queries', 'presence_logit_dec', 'pred_logits', 'pred_boxes', 'pred_boxes_xyxy', 'pred_masks', 'semantic_seg', 'presence_logit']\n  [ComfyUI] [DEBUG] pred_logits shape: torch.Size([1, 200, 1]), min: -6.9062, max: -1.1406\n  [ComfyUI] [DEBUG] pred_boxes shape: torch.Size([1, 200, 4])\n  [ComfyUI] [DEBUG] pred_masks shape: torch.Size([1, 200, 288, 288])\n  [ComfyUI] [DEBUG] presence_logit_dec: torch.Size([1, 1]), val=[-1.0546875], sigmoid=[0.2578125]\n  [ComfyUI] [DEBUG] out_probs (joint_box_scores, no double presence): min=0.0010, max=0.2422\n  [ComfyUI] [DEBUG] confidence_threshold: 0.2\n  [ComfyUI] [DEBUG] detections above threshold: 6 / 200\n  [ComfyUI] [DEBUG] top-10 probs: ['0.2422', '0.2383', '0.2363', '0.2354', '0.2354', '0.2295', '0.0233', '0.0192', '0.0188', '0.0186']\n  [ComfyUI] [DEBUG] after threshold: 6 detections\n  [ComfyUI] [DEBUG] after NMS (iou_thresh=0.5): 6 detections (suppressed 0)\n  [ComfyUI] Found 6 detections above threshold 0.2\n  [ComfyUI] Sorting 6 detections by score...\n  [ComfyUI] Creating visualization...\n  [ComfyUI] Detection complete: 6 masks"}, {"file": "frame_004.jpg", "time": 7.77, "log": "Capturing execution frames: image_seg_text.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  [ComfyUI] Received JSON with keys: ['prompt']\n  Queuing workflow for execution...\n  [ComfyUI] Prompt has 5 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"13\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"13\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 13: SAM3Grounding\n  [ComfyUI]     Inputs: {\"confidence_threshold\": 0.2, \"text_prompt\": \"person\", \"max_detections\": -1, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0]}\n  [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 2 saved (frame_001.jpg, t=2.4s)\n  [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Running text-based detection\n  [ComfyUI]   Text prompt: 'person'\n  [ComfyUI] Confidence threshold: 0.2\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] Adding text prompt...\n  [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0\n  [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557\n  [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29\n  [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  Frame 3 saved (frame_002.jpg, t=4.7s)\n  [capture-periodic] freeze=5ms shot=224ms unfreeze=7ms saved=True\n  [ComfyUI] Encoder.forward OUT:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] _run_encoder output:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000\n  [ComfyUI] _run_decoder inputs:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] Decoder.forward IN:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250\n  [ComfyUI] Decoder.forward OUT:   output=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   ref_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   presence=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _run_decoder output:   hs=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   reference_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores_and_boxes:   hs=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000\n  [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188\n  [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336\n  [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.bfloat16 [6, 1, 200, 1] min=-6.9062 max=-1.0547\n  [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]   obj_queries=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375\n  [ComfyUI] SegHead.forward OUT:   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   semantic_seg=torch.bfloat16 [1, 1, 288, 288] min=-35.5000 max=13.5000   presence_logit=None\n  [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.bfloat16 [1, 200, 1] min=-6.9062 max=-1.1406   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844\n  [ComfyUI] [DEBUG] forward_grounding output keys: ['encoder_hidden_states', 'prev_encoder_out', 'presence_feats', 'queries', 'presence_logit_dec', 'pred_logits', 'pred_boxes', 'pred_boxes_xyxy', 'pred_masks', 'semantic_seg', 'presence_logit']\n  [ComfyUI] [DEBUG] pred_logits shape: torch.Size([1, 200, 1]), min: -6.9062, max: -1.1406\n  [ComfyUI] [DEBUG] pred_boxes shape: torch.Size([1, 200, 4])\n  [ComfyUI] [DEBUG] pred_masks shape: torch.Size([1, 200, 288, 288])\n  [ComfyUI] [DEBUG] presence_logit_dec: torch.Size([1, 1]), val=[-1.0546875], sigmoid=[0.2578125]\n  [ComfyUI] [DEBUG] out_probs (joint_box_scores, no double presence): min=0.0010, max=0.2422\n  [ComfyUI] [DEBUG] confidence_threshold: 0.2\n  [ComfyUI] [DEBUG] detections above threshold: 6 / 200\n  [ComfyUI] [DEBUG] top-10 probs: ['0.2422', '0.2383', '0.2363', '0.2354', '0.2354', '0.2295', '0.0233', '0.0192', '0.0188', '0.0186']\n  [ComfyUI] [DEBUG] after threshold: 6 detections\n  [ComfyUI] [DEBUG] after NMS (iou_thresh=0.5): 6 detections (suppressed 0)\n  [ComfyUI] Found 6 detections above threshold 0.2\n  [ComfyUI] Sorting 6 detections by score...\n  [ComfyUI] Creating visualization...\n  [ComfyUI] Detection complete: 6 masks\n  [capture-loop] iter=50 t=7.0s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=7\n  [ComfyUI] Prompt executed in 6.90 seconds\n  Frame 4 saved (frame_003.jpg, t=7.0s)\n  [capture-periodic] freeze=23ms shot=191ms unfreeze=5ms saved=True"}, {"file": "frame_005.jpg", "time": 11.82822871208191, "log": "Final screenshot"}], "total_time": 8.26}, "image_seg_point": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: image_seg_point.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34."}, {"file": "frame_001.jpg", "time": 1.97, "log": "Capturing execution frames: image_seg_point.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 6 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 15: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":426.27735719657574,\\\"y\\\":321.42611685978835},{\\\"x\\\":417.13743597288953,\\\"y\\\":407.3413796907987},{\\\"x\\\":431.76130993078743,\\\"y\\\":549.9241563039649}],\\\"negative\\\"\n  [ComfyUI]   Node 24: SAM3Segmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 4, \"use_multimask\": false, \"output_best_mask\": false, \"sam3_model\": [\"30\", 0], \"image\": [\"1\", 0], \"positive_points\": [\"15\", 0]}\n  [ComfyUI]   Node 28: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"24\", 2]}\n  [ComfyUI]   Node 29: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"24\", 0]}\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI] Generated prompt_id: 3ea68f8c-ab02-4a8d-b790-94ae457651b8\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d9204c29\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 1280x720\n  [ComfyUI]   Positive point: (426.3, 321.4) -> (0.333, 0.446)\n  [ComfyUI]   Positive point: (417.1, 407.3) -> (0.326, 0.566)\n  [ComfyUI]   Positive point: (431.8, 549.9) -> (0.337, 0.764)\n  [ComfyUI] Output: 3 positive, 0 negative"}, {"file": "frame_002.jpg", "time": 23.26, "log": "Capturing execution frames: image_seg_point.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 6 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 15: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":426.27735719657574,\\\"y\\\":321.42611685978835},{\\\"x\\\":417.13743597288953,\\\"y\\\":407.3413796907987},{\\\"x\\\":431.76130993078743,\\\"y\\\":549.9241563039649}],\\\"negative\\\"\n  [ComfyUI]   Node 24: SAM3Segmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 4, \"use_multimask\": false, \"output_best_mask\": false, \"sam3_model\": [\"30\", 0], \"image\": [\"1\", 0], \"positive_points\": [\"15\", 0]}\n  [ComfyUI]   Node 28: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"24\", 2]}\n  [ComfyUI]   Node 29: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"24\", 0]}\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI] Generated prompt_id: 3ea68f8c-ab02-4a8d-b790-94ae457651b8\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d9204c29\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 1280x720\n  [ComfyUI]   Positive point: (426.3, 321.4) -> (0.333, 0.446)\n  [ComfyUI]   Positive point: (417.1, 407.3) -> (0.326, 0.566)\n  [ComfyUI]   Positive point: (431.8, 549.9) -> (0.337, 0.764)\n  [ComfyUI] Output: 3 positive, 0 negative\n  Node executed (1 total), capturing...\n  Frame 2 saved (frame_001.jpg, t=2.0s)\n  [capture-node] freeze=37ms shot=246ms unfreeze=7ms saved=True\n  [ComfyUI] Model not found at /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors, downloading from HuggingFace...\n  [ComfyUI] HTTP Request: HEAD https://huggingface.co/apozz/sam3-safetensors/resolve/main/sam3.safetensors \"HTTP/1.1 302 Found\"\n  [ComfyUI] HTTP Request: GET https://huggingface.co/api/models/apozz/sam3-safetensors/xet-read-token/e88da2ed02aded4006f4711ee6a9c75d5aa38d0c \"HTTP/1.1 200 OK\"\n  [capture-loop] iter=50 t=8.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=13\n  [capture-loop] iter=100 t=15.4s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=11\n  [capture-loop] iter=150 t=21.9s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=3\n  [ComfyUI] Model downloaded to: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Using click-based interactive segmentation\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000"}, {"file": "frame_003.jpg", "time": 38.63, "log": "Capturing execution frames: image_seg_point.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 6 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"example_image.jpg\"}\n  [ComfyUI]   Node 15: SAM3PointCollector\n  [ComfyUI]     Inputs: {\"points_store\": \"{\\\"positive\\\":[{\\\"x\\\":426.27735719657574,\\\"y\\\":321.42611685978835},{\\\"x\\\":417.13743597288953,\\\"y\\\":407.3413796907987},{\\\"x\\\":431.76130993078743,\\\"y\\\":549.9241563039649}],\\\"negative\\\"\n  [ComfyUI]   Node 24: SAM3Segmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 4, \"use_multimask\": false, \"output_best_mask\": false, \"sam3_model\": [\"30\", 0], \"image\": [\"1\", 0], \"positive_points\": [\"15\", 0]}\n  [ComfyUI]   Node 28: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"24\", 2]}\n  [ComfyUI]   Node 29: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"24\", 0]}\n  [ComfyUI]   Node 30: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI] Generated prompt_id: 3ea68f8c-ab02-4a8d-b790-94ae457651b8\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  [ComfyUI] CACHE MISS - computing new result for key=d9204c29\n  [ComfyUI] Collected 3 positive, 0 negative points\n  [ComfyUI] Image dimensions: 1280x720\n  [ComfyUI]   Positive point: (426.3, 321.4) -> (0.333, 0.446)\n  [ComfyUI]   Positive point: (417.1, 407.3) -> (0.326, 0.566)\n  [ComfyUI]   Positive point: (431.8, 549.9) -> (0.337, 0.764)\n  [ComfyUI] Output: 3 positive, 0 negative\n  Node executed (1 total), capturing...\n  Frame 2 saved (frame_001.jpg, t=2.0s)\n  [capture-node] freeze=37ms shot=246ms unfreeze=7ms saved=True\n  [ComfyUI] Model not found at /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors, downloading from HuggingFace...\n  [ComfyUI] HTTP Request: HEAD https://huggingface.co/apozz/sam3-safetensors/resolve/main/sam3.safetensors \"HTTP/1.1 302 Found\"\n  [ComfyUI] HTTP Request: GET https://huggingface.co/api/models/apozz/sam3-safetensors/xet-read-token/e88da2ed02aded4006f4711ee6a9c75d5aa38d0c \"HTTP/1.1 200 OK\"\n  [capture-loop] iter=50 t=8.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=13\n  [capture-loop] iter=100 t=15.4s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=11\n  [capture-loop] iter=150 t=21.9s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=3\n  [ComfyUI] Model downloaded to: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  [ComfyUI] Using click-based interactive segmentation\n  [ComfyUI] Image size: (1280, 720)\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000\n  Frame 3 saved (frame_002.jpg, t=23.3s)\n  [capture-periodic] freeze=5ms shot=397ms unfreeze=7ms saved=True\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000\n  [ComfyUI] sam2_backbone_out is available\n  [ComfyUI] Added 3 positive points\n  [ComfyUI] Points: 3\n  [ComfyUI]   Coords: [[426.27735719657574, 321.42611685978835], [417.13743597288953, 407.3413796907987], [431.76130993078743, 549.9241563039649]]\n  [ComfyUI]   Labels: [1, 1, 1]\n  [ComfyUI] Refinement 1/4, best score: 0.9648\n  [ComfyUI] Refinement 2/4, best score: 0.9688\n  [ComfyUI] Refinement 3/4, best score: 0.9688\n  [ComfyUI] Refinement 4/4, best score: 0.9688\n  [ComfyUI] Prediction returned 1 masks\n  [ComfyUI]   Mask shape: (1, 720, 1280)\n  [ComfyUI]   Low-res shape: (1, 288, 288)\n  [ComfyUI]   Scores: [0.96875]"}, {"file": "frame_004.jpg", "time": 43.071945905685425, "log": "Final screenshot"}], "total_time": 39.11}, "scene_seg": {"frames": [{"file": "frame_000.jpg", "time": 0.0, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34."}, {"file": "frame_001.jpg", "time": 3.02, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'"}, {"file": "frame_002.jpg", "time": 7.79, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead."}, {"file": "frame_003.jpg", "time": 10.49, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Node executed (1 total), capturing...\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 3 saved (frame_002.jpg, t=7.8s)\n  [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity"}, {"file": "frame_004.jpg", "time": 33.33, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Node executed (1 total), capturing...\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 3 saved (frame_002.jpg, t=7.8s)\n  [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  Frame 4 saved (frame_003.jpg, t=10.5s)\n  [ComfyUI] Image size: (6720, 4480)\n  [capture-periodic] freeze=4ms shot=204ms unfreeze=5ms saved=True\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [ComfyUI] Processing prompt region 1/7\n  [ComfyUI]   Points: 10, Box: Yes\n  [ComfyUI]   Mask score: 0.9805\n  [ComfyUI] Processing prompt region 2/7\n  [ComfyUI]   Points: 23, Box: Yes\n  [ComfyUI]   Mask score: 0.9414\n  [ComfyUI] Processing prompt region 3/7\n  [ComfyUI]   Points: 21, Box: Yes\n  [capture-loop] iter=50 t=12.1s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [ComfyUI]   Mask score: 0.9023\n  [ComfyUI] Processing prompt region 4/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9766\n  [ComfyUI] Processing prompt region 5/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9844\n  [ComfyUI] Processing prompt region 6/7\n  [ComfyUI]   Points: 13, Box: Yes\n  [ComfyUI]   Mask score: 0.9883\n  [ComfyUI] Processing prompt region 7/7\n  [ComfyUI]   Points: 6, Box: Yes\n  [ComfyUI]   Mask score: 0.9688\n  [ComfyUI] Generated 7 masks\n  [capture-loop] iter=100 t=18.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [capture-loop] iter=150 t=24.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [capture-loop] iter=200 t=31.0s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=8"}, {"file": "frame_005.jpg", "time": 38.16, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Node executed (1 total), capturing...\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 3 saved (frame_002.jpg, t=7.8s)\n  [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  Frame 4 saved (frame_003.jpg, t=10.5s)\n  [ComfyUI] Image size: (6720, 4480)\n  [capture-periodic] freeze=4ms shot=204ms unfreeze=5ms saved=True\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [ComfyUI] Processing prompt region 1/7\n  [ComfyUI]   Points: 10, Box: Yes\n  [ComfyUI]   Mask score: 0.9805\n  [ComfyUI] Processing prompt region 2/7\n  [ComfyUI]   Points: 23, Box: Yes\n  [ComfyUI]   Mask score: 0.9414\n  [ComfyUI] Processing prompt region 3/7\n  [ComfyUI]   Points: 21, Box: Yes\n  [capture-loop] iter=50 t=12.1s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [ComfyUI]   Mask score: 0.9023\n  [ComfyUI] Processing prompt region 4/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9766\n  [ComfyUI] Processing prompt region 5/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9844\n  [ComfyUI] Processing prompt region 6/7\n  [ComfyUI]   Points: 13, Box: Yes\n  [ComfyUI]   Mask score: 0.9883\n  [ComfyUI] Processing prompt region 7/7\n  [ComfyUI]   Points: 6, Box: Yes\n  [ComfyUI]   Mask score: 0.9688\n  [ComfyUI] Generated 7 masks\n  [capture-loop] iter=100 t=18.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [capture-loop] iter=150 t=24.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [capture-loop] iter=200 t=31.0s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=8\n  Frame 5 saved (frame_004.jpg, t=33.3s)\n  [capture-periodic] freeze=4ms shot=212ms unfreeze=10ms saved=True\n  [capture-loop] iter=250 t=37.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4"}, {"file": "frame_006.jpg", "time": 48.91, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Node executed (1 total), capturing...\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 3 saved (frame_002.jpg, t=7.8s)\n  [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  Frame 4 saved (frame_003.jpg, t=10.5s)\n  [ComfyUI] Image size: (6720, 4480)\n  [capture-periodic] freeze=4ms shot=204ms unfreeze=5ms saved=True\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [ComfyUI] Processing prompt region 1/7\n  [ComfyUI]   Points: 10, Box: Yes\n  [ComfyUI]   Mask score: 0.9805\n  [ComfyUI] Processing prompt region 2/7\n  [ComfyUI]   Points: 23, Box: Yes\n  [ComfyUI]   Mask score: 0.9414\n  [ComfyUI] Processing prompt region 3/7\n  [ComfyUI]   Points: 21, Box: Yes\n  [capture-loop] iter=50 t=12.1s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [ComfyUI]   Mask score: 0.9023\n  [ComfyUI] Processing prompt region 4/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9766\n  [ComfyUI] Processing prompt region 5/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9844\n  [ComfyUI] Processing prompt region 6/7\n  [ComfyUI]   Points: 13, Box: Yes\n  [ComfyUI]   Mask score: 0.9883\n  [ComfyUI] Processing prompt region 7/7\n  [ComfyUI]   Points: 6, Box: Yes\n  [ComfyUI]   Mask score: 0.9688\n  [ComfyUI] Generated 7 masks\n  [capture-loop] iter=100 t=18.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [capture-loop] iter=150 t=24.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [capture-loop] iter=200 t=31.0s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=8\n  Frame 5 saved (frame_004.jpg, t=33.3s)\n  [capture-periodic] freeze=4ms shot=212ms unfreeze=10ms saved=True\n  [capture-loop] iter=250 t=37.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Node executed (2 total), capturing...\n  Frame 6 saved (frame_005.jpg, t=38.2s)\n  [capture-node] freeze=247ms shot=1271ms unfreeze=9ms saved=True\n  [capture-loop] iter=300 t=45.6s state={'complete': False, 'error': None, 'executedCount': 2, 'wsState': 1} eval_ms=5"}, {"file": "frame_007.jpg", "time": 50.61, "log": "Capturing execution frames: scene_seg.json\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)\n  [Console-warning] [ComfyUI Notice] \"extensions/core/widgetInputs.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Notice] \"scripts/utils.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Notice] \"scripts/widgets.js\" is an internal module, not part of the public API. Future updates may break this import.\n  [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/buttonGroup.js\" is deprecated and will be removed in v1.34.\n  [Console-warning] [ComfyUI Deprecated] Importing from \"scripts/ui/components/button.js\" is deprecated and will be removed in v1.34.\n  Frame 1 saved (frame_000.jpg, t=0.0s)\n  Validating workflow...\n  [ComfyUI] === /validate endpoint called ===\n  Queuing workflow for execution...\n  [ComfyUI] Received JSON with keys: ['prompt']\n  [ComfyUI] Prompt has 10 nodes\n  [ComfyUI]   Node 1: LoadImage\n  [ComfyUI]     Inputs: {\"image\": \"image.png\"}\n  [ComfyUI]   Node 3: PreviewImage\n  [ComfyUI]     Inputs: {\"images\": [\"21\", 1]}\n  [ComfyUI]   Node 4: MaskPreview\n  [ComfyUI]     Inputs: {\"mask\": [\"21\", 0]}\n  [ComfyUI]   Node 12: LoadSAM3Model\n  [ComfyUI]     Inputs: {\"precision\": \"auto\", \"attention\": \"auto\", \"compile\": false}\n  [ComfyUI]   Node 20: SAM3MultiRegionCollector\n  [ComfyUI]     Inputs: {\"multi_prompts_store\": \"[{\\\"positive_points\\\":[{\\\"x\\\":5052.74953932266,\\\"y\\\":2847.0600693869637},{\\\"x\\\":4932.510591392486,\\\"y\\\":2953.9413227753366},{\\\"x\\\":4718.752461738845,\\\"y\\\":2967.301479448883},{\n  [ComfyUI]   Node 21: SAM3MultipromptSegmentation\n  [ComfyUI]     Inputs: {\"refinement_iterations\": 2, \"use_multimask\": false, \"sam3_model\": [\"12\", 0], \"image\": [\"1\", 0], \"multi_prompts\": [\"20\", 0]}\n  [ComfyUI]   Node 22: MultibandFromBatch\n  [ComfyUI]     Inputs: {\"images\": [\"1\", 0], \"masks\": [\"21\", 0]}\n  [ComfyUI]   Node 23: MultibandSave\n  [ComfyUI]     Inputs: {\"file_path\": \"output/multiband\", \"format\": \"npz\", \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 24: MultibandPreview\n  [ComfyUI]     Inputs: {\"channel_index\": 0, \"multiband\": [\"26\", 0]}\n  [ComfyUI]   Node 26: MultibandResize\n  [ComfyUI]     Inputs: {\"upscale_method\": \"nearest-exact\", \"width\": 900, \"height\": 600, \"crop\": \"center\", \"multiband\": [\"22\", 0]}\n  [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1\n  [ComfyUI] Calling execution.validate_prompt()...\n  [ComfyUI] Validation result: valid=True\n  [ComfyUI] === Validation PASSED ===\n  [ComfyUI] got prompt\n  [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'\n  Frame 2 saved (frame_001.jpg, t=3.0s)\n  [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True\n  [ComfyUI] CACHE MISS - computing new result for key=35316a77\n  [ComfyUI] Image dimensions: 6720x4480\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes\n  [ComfyUI] Output: 7 non-empty prompts\n  [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Sam3VideoPredictor using device: cuda:0\n  [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.\n  Node executed (1 total), capturing...\n  [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16\n  [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors\n  [ComfyUI] Added 309 keys for detector.inst_interactive_predictor\n  Frame 3 saved (frame_002.jpg, t=7.8s)\n  [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True\n  [ComfyUI] Model ready (1756.7 MB)\n  [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity\n  Frame 4 saved (frame_003.jpg, t=10.5s)\n  [ComfyUI] Image size: (6720, 4480)\n  [capture-periodic] freeze=4ms shot=204ms unfreeze=5ms saved=True\n  [ComfyUI] Processing 7 prompt regions\n  [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0\n  [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531\n  [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16\n  [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]\n  [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]\n  [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]\n  [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']\n  [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539\n  [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375\n  [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625\n  [ComfyUI] Processing prompt region 1/7\n  [ComfyUI]   Points: 10, Box: Yes\n  [ComfyUI]   Mask score: 0.9805\n  [ComfyUI] Processing prompt region 2/7\n  [ComfyUI]   Points: 23, Box: Yes\n  [ComfyUI]   Mask score: 0.9414\n  [ComfyUI] Processing prompt region 3/7\n  [ComfyUI]   Points: 21, Box: Yes\n  [capture-loop] iter=50 t=12.1s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [ComfyUI]   Mask score: 0.9023\n  [ComfyUI] Processing prompt region 4/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9766\n  [ComfyUI] Processing prompt region 5/7\n  [ComfyUI]   Points: 1, Box: Yes\n  [ComfyUI]   Mask score: 0.9844\n  [ComfyUI] Processing prompt region 6/7\n  [ComfyUI]   Points: 13, Box: Yes\n  [ComfyUI]   Mask score: 0.9883\n  [ComfyUI] Processing prompt region 7/7\n  [ComfyUI]   Points: 6, Box: Yes\n  [ComfyUI]   Mask score: 0.9688\n  [ComfyUI] Generated 7 masks\n  [capture-loop] iter=100 t=18.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  [capture-loop] iter=150 t=24.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5\n  [capture-loop] iter=200 t=31.0s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=8\n  Frame 5 saved (frame_004.jpg, t=33.3s)\n  [capture-periodic] freeze=4ms shot=212ms unfreeze=10ms saved=True\n  [capture-loop] iter=250 t=37.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4\n  Node executed (2 total), capturing...\n  Frame 6 saved (frame_005.jpg, t=38.2s)\n  [capture-node] freeze=247ms shot=1271ms unfreeze=9ms saved=True\n  [capture-loop] iter=300 t=45.6s state={'complete': False, 'error': None, 'executedCount': 2, 'wsState': 1} eval_ms=5\n  Node executed (3 total), capturing...\n  Frame 7 saved (frame_006.jpg, t=48.9s)\n  [capture-node] freeze=4ms shot=204ms unfreeze=7ms saved=True"}, {"file": "frame_008.jpg", "time": 56.08278942108154, "log": "Final screenshot"}], "total_time": 51.13}};

        let currentWorkflow = null;
        let playInterval = null;
        let originalLogContent = '';
        let currentFrameIndex = 0;
        let currentFrames = [];
        let currentTotalTime = 0;

        function openLightboxByName(name) {
            const w = workflowData[name];
            if (w) openLightbox(w.src, w.title, w.status, w.duration, w.log, w.hardware);
        }

        function openLightbox(src, title, status, duration, logContent, hardware) {
            document.getElementById('lightbox-img').src = src;
            document.getElementById('lightbox-title').textContent = title;
            currentWorkflow = title;
            originalLogContent = logContent;

            const badge = document.getElementById('lightbox-badge');
            badge.textContent = status;
            badge.className = 'lightbox-badge ' + status;

            document.getElementById('lightbox-duration').textContent = duration + 's';
            document.getElementById('lightbox-log').textContent = logContent || '(No log available)';

            const hwEl = document.getElementById('lightbox-hardware');
            if (hardware) {
                const parts = [];
                if (hardware.os) parts.push(hardware.os);
                if (hardware.cpu) parts.push(hardware.cpu);
                if (hardware.gpu) parts.push(hardware.gpu);
                hwEl.textContent = parts.join(' | ');
            } else {
                hwEl.textContent = status === 'skipped' ? '(Did not run on this machine)' : '';
            }

            const data = videoData[title];
            const videoPlayer = document.getElementById('video-player');

            if (data && data.frames && data.frames.length > 1) {
                currentFrames = data.frames;
                currentTotalTime = data.total_time || data.frames[data.frames.length - 1].time;
                setupVideoSlider(data.frames, currentTotalTime);
                updateVideoFrameByIndex(title, data.frames.length - 1);
                videoPlayer.classList.add('active');
            } else {
                videoPlayer.classList.remove('active');
            }

            loadResourceGraph(title);

            document.getElementById('lightbox').classList.add('active');
            history.replaceState(null, '', '#' + encodeURIComponent(title));
        }

        function buildSliderRange(frames, totalTime) {
            const range = { 'min': frames[0].time };
            frames.forEach((frame, idx) => {
                if (idx > 0 && idx < frames.length - 1) {
                    const pct = (frame.time / totalTime * 100).toFixed(1) + '%';
                    range[pct] = frame.time;
                }
            });
            range['max'] = frames[frames.length - 1].time;
            return range;
        }

        function setupVideoSlider(frames, totalTime) {
            const sliderEl = document.getElementById('video-slider');

            if (sliderEl.noUiSlider) {
                sliderEl.noUiSlider.destroy();
            }

            const range = buildSliderRange(frames, totalTime);

            noUiSlider.create(sliderEl, {
                start: frames[frames.length - 1].time,
                snap: true,
                range: range,
                pips: {
                    mode: 'range',
                    density: 100
                }
            });

            sliderEl.noUiSlider.on('update', function(values) {
                const time = parseFloat(values[0]);
                const frameIdx = frames.findIndex(f => Math.abs(f.time - time) < 0.01);
                if (frameIdx >= 0 && frameIdx !== currentFrameIndex) {
                    currentFrameIndex = frameIdx;
                    showFrame(currentWorkflow, frameIdx);
                }
            });
        }

        function showFrame(workflowName, frameIndex) {
            const data = videoData[workflowName];
            if (!data || !data.frames) return;

            const frame = data.frames[frameIndex];
            const img = document.getElementById('lightbox-img');

            const isLastFrame = frameIndex === data.frames.length - 1;
            if (isLastFrame && workflowData[workflowName] && workflowData[workflowName].src) {
                img.src = workflowData[workflowName].src;
            } else {
                img.src = 'videos/' + workflowName + '/' + frame.file;
            }

            const counter = document.getElementById('video-frame-counter');
            const totalTime = data.total_time || data.frames[data.frames.length - 1].time;
            counter.textContent = frame.time.toFixed(1) + 's / ' + totalTime.toFixed(1) + 's';

            const logEl = document.getElementById('lightbox-log');
            if (frame.log) {
                logEl.textContent = frame.log;
                logEl.scrollTop = logEl.scrollHeight;
            }
        }

        function updateVideoFrameByIndex(workflowName, frameIndex) {
            currentFrameIndex = frameIndex;
            showFrame(workflowName, frameIndex);

            const sliderEl = document.getElementById('video-slider');
            if (sliderEl.noUiSlider && currentFrames[frameIndex]) {
                sliderEl.noUiSlider.set(currentFrames[frameIndex].time);
            }
        }

        function toggleVideoPlay() {
            const btn = document.getElementById('video-play-btn');
            if (playInterval) {
                clearInterval(playInterval);
                playInterval = null;
                btn.innerHTML = '&#9654; Play';
            } else {
                btn.innerHTML = '&#9632; Stop';
                playInterval = setInterval(() => {
                    if (!currentFrames.length) return;
                    currentFrameIndex = (currentFrameIndex + 1) % currentFrames.length;
                    updateVideoFrameByIndex(currentWorkflow, currentFrameIndex);
                }, 500);
            }
        }

        let resourceGraphState = null;

        async function loadResourceGraph(workflowName) {
            const graphContainer = document.getElementById('resource-graph');
            const canvas = document.getElementById('resource-canvas');
            const gpuLegend = document.getElementById('gpu-legend');

            resourceGraphState = null;

            try {
                const csvResponse = await fetch('logs/' + workflowName + '_resources.csv');

                if (!csvResponse.ok) {
                    graphContainer.classList.remove('active');
                    return;
                }

                const text = await csvResponse.text();
                const allLines = text.trim().split('\n');

                let totalRamGb = 32;
                if (allLines[0].startsWith('#')) {
                    const metaMatch = allLines[0].match(/total_ram_gb=([\d.]+)/);
                    if (metaMatch) {
                        totalRamGb = parseFloat(metaMatch[1]);
                    }
                }

                const dataLines = allLines.slice(2);

                if (dataLines.length < 2) {
                    graphContainer.classList.remove('active');
                    return;
                }

                const data = dataLines.map(line => {
                    const [t, ram, vram] = line.split(',');
                    return {
                        t: parseFloat(t),
                        ram: parseFloat(ram),
                        vram: vram ? parseFloat(vram) : null
                    };
                });

                const hasVram = data.some(d => d.vram !== null);
                gpuLegend.style.display = hasVram ? 'flex' : 'none';

                graphContainer.classList.add('active');
                await new Promise(r => setTimeout(r, 10));

                const ctx = canvas.getContext('2d');
                const dpr = window.devicePixelRatio || 1;
                const rect = canvas.getBoundingClientRect();
                canvas.width = rect.width * dpr;
                canvas.height = rect.height * dpr;
                ctx.scale(dpr, dpr);

                const w = rect.width;
                const h = rect.height;
                const padding = { top: 10, right: 40, bottom: 20, left: 45 };
                const graphW = w - padding.left - padding.right;
                const graphH = h - padding.top - padding.bottom;

                const maxRam = Math.max(...data.map(d => d.ram), 0.5);
                const maxVram = hasVram ? Math.max(...data.filter(d => d.vram !== null).map(d => d.vram), 0.5) : 1;
                const maxTime = data[data.length - 1].t;

                resourceGraphState = { data, padding, w, h, graphW, graphH, maxRam, maxVram, maxTime, hasVram, dpr };

                drawResourceGraph();
            } catch (e) {
                console.error('Resource graph error:', e);
                graphContainer.classList.remove('active');
            }
        }

        function drawResourceGraph(hoverX) {
            if (!resourceGraphState) return;
            const { data, padding, w, h, graphW, graphH, maxRam, maxVram, maxTime, hasVram, dpr } = resourceGraphState;

            const canvas = document.getElementById('resource-canvas');
            const ctx = canvas.getContext('2d');
            ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
            ctx.clearRect(0, 0, w, h);

            // Grid lines
            ctx.strokeStyle = '#1c2d44';
            ctx.lineWidth = 0.5;
            for (let i = 1; i < 4; i++) {
                const y = padding.top + (graphH * i / 4);
                ctx.beginPath();
                ctx.moveTo(padding.left, y);
                ctx.lineTo(w - padding.right, y);
                ctx.stroke();
            }

            // Axes
            ctx.strokeStyle = '#243656';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(padding.left, padding.top);
            ctx.lineTo(padding.left, h - padding.bottom);
            ctx.lineTo(w - padding.right, h - padding.bottom);
            ctx.lineTo(w - padding.right, padding.top);
            ctx.stroke();

            // Left axis: RAM
            ctx.fillStyle = '#3fb950';
            ctx.font = '9px sans-serif';
            ctx.textAlign = 'right';
            const ramMax = Math.ceil(maxRam * 10) / 10;
            ctx.fillText(ramMax.toFixed(1) + ' GB', padding.left - 3, padding.top + 4);
            ctx.fillText('0', padding.left - 3, h - padding.bottom + 4);

            // Right axis: VRAM (if present)
            if (hasVram) {
                ctx.fillStyle = '#d29922';
                ctx.textAlign = 'left';
                const vramMax = Math.ceil(maxVram * 10) / 10;
                ctx.fillText(vramMax.toFixed(1) + ' GB', w - padding.right + 3, padding.top + 4);
                ctx.fillText('0', w - padding.right + 3, h - padding.bottom + 4);
            }

            // Time labels
            ctx.fillStyle = '#4a6282';
            ctx.textAlign = 'center';
            ctx.fillText('0s', padding.left, h - padding.bottom + 12);
            ctx.fillText(maxTime.toFixed(0) + 's', w - padding.right, h - padding.bottom + 12);

            function drawLine(values, maxVal, color) {
                if (values.every(v => v === null || isNaN(v))) return;
                ctx.strokeStyle = color;
                ctx.lineWidth = 1.5;
                ctx.beginPath();
                let started = false;
                data.forEach((d, i) => {
                    const val = values[i];
                    if (val === null || isNaN(val)) return;
                    const x = padding.left + (d.t / maxTime) * graphW;
                    const y = padding.top + (1 - val / maxVal) * graphH;
                    if (!started) { ctx.moveTo(x, y); started = true; }
                    else { ctx.lineTo(x, y); }
                });
                ctx.stroke();
            }

            drawLine(data.map(d => d.ram), ramMax, '#3fb950');
            if (hasVram) {
                drawLine(data.map(d => d.vram), Math.ceil(maxVram * 10) / 10, '#d29922');
            }

            // Hover crosshair
            if (hoverX !== undefined && hoverX >= padding.left && hoverX <= w - padding.right) {
                const timeAtCursor = ((hoverX - padding.left) / graphW) * maxTime;
                let closest = data[0], closestDist = Infinity;
                for (const d of data) {
                    const dist = Math.abs(d.t - timeAtCursor);
                    if (dist < closestDist) { closestDist = dist; closest = d; }
                }

                const snapX = padding.left + (closest.t / maxTime) * graphW;

                // Vertical line
                ctx.strokeStyle = 'rgba(230,237,243,0.2)';
                ctx.lineWidth = 1;
                ctx.beginPath();
                ctx.moveTo(snapX, padding.top);
                ctx.lineTo(snapX, h - padding.bottom);
                ctx.stroke();

                // Readout
                ctx.font = '10px sans-serif';
                ctx.textAlign = 'left';
                const readoutX = snapX + 6;
                let readoutY = padding.top + 14;

                ctx.fillStyle = '#8ba3c1';
                ctx.fillText(closest.t.toFixed(1) + 's', readoutX, readoutY);
                readoutY += 13;

                ctx.fillStyle = '#3fb950';
                ctx.fillText('RAM: ' + closest.ram.toFixed(2) + ' GB', readoutX, readoutY);
                readoutY += 13;

                if (hasVram && closest.vram !== null) {
                    ctx.fillStyle = '#d29922';
                    ctx.fillText('VRAM: ' + closest.vram.toFixed(2) + ' GB', readoutX, readoutY);
                }
            }
        }

        // Canvas hover handler
        document.getElementById('resource-canvas').addEventListener('mousemove', function(e) {
            if (!resourceGraphState) return;
            const rect = this.getBoundingClientRect();
            drawResourceGraph(e.clientX - rect.left);
        });
        document.getElementById('resource-canvas').addEventListener('mouseleave', function() {
            drawResourceGraph();
        });

        function closeLightbox() {
            if (playInterval) {
                clearInterval(playInterval);
                playInterval = null;
                document.getElementById('video-play-btn').innerHTML = '&#9654; Play';
            }
            document.getElementById('resource-graph').classList.remove('active');
            document.getElementById('lightbox').classList.remove('active');
            history.replaceState(null, '', window.location.pathname);
        }

        document.getElementById('lightbox').onclick = (e) => {
            if (e.target.id === 'lightbox') closeLightbox();
        };

        document.onkeydown = (e) => {
            if (e.key === 'Escape') closeLightbox();
        };

        function openFromHash() {
            const hash = decodeURIComponent(window.location.hash.slice(1));
            if (hash && workflowData[hash]) {
                const w = workflowData[hash];
                openLightbox(w.src, w.title, w.status, w.duration, w.log, w.hardware);
            }
        }

        window.addEventListener('hashchange', openFromHash);
        window.addEventListener('load', openFromHash);

        // Detect iframe: hide header and move meta chips into summary
        if (window !== window.top) {
            document.body.classList.add('in-iframe');
            const chips = document.querySelector('.meta-chips');
            const summary = document.querySelector('.summary');
            if (chips && summary) {
                const wrapper = document.createElement('div');
                wrapper.className = 'summary-meta';
                while (chips.firstChild) wrapper.appendChild(chips.firstChild);
                summary.insertBefore(wrapper, summary.firstChild);
            }
        }
    </script>
</body>
</html>
