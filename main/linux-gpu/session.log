[00:00] Crash dump logging enabled: /home/shadeform/logs/SAM3-0057/dev/linux-gpu/crash_dump.log
[00:00] 
[00:00] [1/5] SYNTAX
[00:00] ----------------------------------------
[00:00] [DEBUG] server=None, server_url=None, api=None
[00:00] Found pyproject.toml (modern format)
[00:00] Found requirements.txt (legacy format)
[00:00] Unicode check: OK (all characters cp1252-safe)
[00:00] Forbidden patterns check: OK
[00:00] [SYNTAX] PASSED
[00:00] 
[00:00] [2/5] INSTALL
[00:00] ----------------------------------------
[00:00] [DEBUG] server=None, server_url=None, api=None
[00:00] Setting up ComfyUI...
[00:00] Creating virtual environment...
[00:00] Running: uv venv /home/shadeform/workspaces/SAM3-0057/.venv --python 3.10
[00:00] Cloning ComfyUI (latest)...
[00:00] Running: git clone --depth 1 https://github.com/comfyanonymous/ComfyUI.git /home/shadeform/workspaces/SAM3-0057/ComfyUI
[00:01] Installing ComfyUI requirements...
[00:01] Running: uv pip install --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python --index-url https://download.pytorch.org/whl/cu128 --extra-index-url https://pypi.org/simple -r /home/shadeform/workspaces/SAM3-0057/ComfyUI/requirements.txt
[00:03] Installing local comfy-env (editable)...
[00:03] Running: uv pip install -e /home/shadeform/utils/comfy-env --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python
[00:04] Installing local comfy-test (editable)...
[00:04] Running: uv pip install -e /home/shadeform/utils/comfy-test --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python
[00:05] Installing local comfy-3d-viewers (editable)...
[00:05] Running: uv pip install -e /home/shadeform/utils/comfy-3d-viewers --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python
[00:06] Installing custom node...
[00:06] Copying ComfyUI-SAM3 to custom_nodes/...
[00:06] Installing node requirements...
[00:06] Running: uv pip install --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python --index-url https://download.pytorch.org/whl/cu128 --extra-index-url https://pypi.org/simple -r /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-SAM3/requirements.txt
[00:07] Running install.py...
[00:07] Running: /home/shadeform/workspaces/SAM3-0057/.venv/bin/python /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-SAM3/install.py
[00:34]   Installing 3 node dependencies...
[00:34]     Cloning ComfyUI-VideoHelperSuite...
[00:34]     Installing requirements for ComfyUI-VideoHelperSuite...
[00:34]     Cloning ComfyUI-Multiband...
[00:34]     Installing requirements for ComfyUI-Multiband...
[00:34]     Cloning ComfyUI-Env-Manager...
[00:34]     Installing requirements for ComfyUI-Env-Manager...
[00:34]   
[00:34]   [requirements] Re-installing main package requirements...
[00:34]     Installing requirements for ComfyUI-SAM3...
[00:34]   
[00:34]   [cuda] Installing to host Python: cc_torch, torch_generic_nms, flash-attn, sageattention
[00:34]   [cuda] Host: Python 3.10, PyTorch 2.10.0, CUDA 12.8
[00:34]     cc_torch: looking up in cuda-wheels index (cu128 torch210 cp310)
[00:34]     cc_torch: found in cuda-wheels index
[00:34]     /home/shadeform/workspaces/SAM3-0057/.venv/bin/uv pip install --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python --no-deps https://github.com/PozzettiAndrea/cuda-wheels/releases/download/cc_torch-latest/cc_torch-0.2%2Bcu128torch210-cp310-cp310-linux_x86_64.whl
[00:34]     torch_generic_nms: looking up in cuda-wheels index (cu128 torch210 cp310)
[00:34]     torch_generic_nms: found in cuda-wheels index
[00:34]     /home/shadeform/workspaces/SAM3-0057/.venv/bin/uv pip install --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python --no-deps https://github.com/PozzettiAndrea/cuda-wheels/releases/download/torch_generic_nms-latest/torch_generic_nms-0.1%2Bcu128torch210-cp310-cp310-manylinux_2_34_x86_64.manylinux_2_35_x86_64.whl
[00:34]     flash-attn: looking up in cuda-wheels index (cu128 torch210 cp310)
[00:34]     flash-attn: found in cuda-wheels index
[00:34]     /home/shadeform/workspaces/SAM3-0057/.venv/bin/uv pip install --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python --no-deps https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.7.12/flash_attn-2.8.3%2Bcu128torch2.10-cp310-cp310-linux_x86_64.whl
[00:34]     sageattention: looking up in cuda-wheels index (cu128 torch210 cp310)
[00:34]     sageattention: found in cuda-wheels index
[00:34]     /home/shadeform/workspaces/SAM3-0057/.venv/bin/uv pip install --python /home/shadeform/workspaces/SAM3-0057/.venv/bin/python --no-deps https://github.com/PozzettiAndrea/cuda-wheels/releases/download/sageattention-latest/sageattention-2.2.0%2Bcu128torch210-cp310-cp310-manylinux_2_34_x86_64.manylinux_2_35_x86_64.whl
[00:34]   
[00:34]   Installation complete!
[00:34] Installing 3 node dependency(ies)...
[00:34]   ComfyUI-VideoHelperSuite from Kosinkadink/ComfyUI-VideoHelperSuite
[00:34]   ComfyUI-VideoHelperSuite already exists, skipping...
[00:34]   ComfyUI-Multiband from PozzettiAndrea/ComfyUI-Multiband
[00:34]   ComfyUI-Multiband already exists, skipping...
[00:34]   ComfyUI-Env-Manager from PozzettiAndrea/ComfyUI-Env-Manager
[00:34]   ComfyUI-Env-Manager already exists, skipping...
[00:34] Installing validation endpoint...
[00:34]   Cloning PozzettiAndrea/ComfyUI-validate-endpoint...
[00:34] Running: git clone --depth 1 https://github.com/PozzettiAndrea/ComfyUI-validate-endpoint.git /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-validate-endpoint
[00:34] COMFY_TEST_GPU env var = '1'
[00:34] GPU mode: using real CUDA (no mocking)
[00:34] [INSTALL] PASSED
[00:34] 
[00:34] [3/5] REGISTRATION
[00:34] ----------------------------------------
[00:34] [DEBUG] server=None, server_url=None, api=None
[00:34] 
Starting ComfyUI server...
[00:34] Starting ComfyUI server on port 41891...
[00:34] Starting ComfyUI server on port 41891...
[00:34] Waiting for server to be ready (timeout: 300s)...
[00:39]   [ComfyUI] [comfy-env] ComfyUI-SAM3: root config found but env not built yet
[00:39]   [ComfyUI] [comfy-env] Library paths (main process):
[00:39]   [ComfyUI] [comfy-env]   PATH=/home/shadeform/.local/bin:/home/shadeform/.local/bin:/home/shadeform/.local/bin:/home/shadeform/.venv/bin:/usr/local/bin:/usr/bin:/bin:/snap/bin
[00:39]   [ComfyUI] [comfy-env] prestartup complete
[00:42]   [ComfyUI] [comfy-env] Auto-enabled sage attention
[00:42]   [ComfyUI] [comfy-env] Auto-enabled flash attention
[00:42]   [ComfyUI] 
[00:42]   [ComfyUI] Prestartup times for custom nodes:
[00:42]   [ComfyUI]    3.6 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-SAM3
[00:42]   [ComfyUI] 
[00:42]   [ComfyUI] WARNING: Potential Error in code: Torch already imported, torch should never be imported before this point.
[00:49]   [ComfyUI] WARNING: You need pytorch with cu130 or higher to use optimized CUDA operations.
[00:49]   [ComfyUI] Found comfy_kitchen backend triton: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}
[00:49]   [ComfyUI] Found comfy_kitchen backend eager: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}
[00:49]   [ComfyUI] Found comfy_kitchen backend cuda: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}
[00:49]   [ComfyUI] Checkpoint files will always be loaded safely.
[00:49]   [ComfyUI] Total VRAM 48539 MB, total RAM 48269 MB
[00:49]   [ComfyUI] pytorch version: 2.10.0+cu128
[00:49]   [ComfyUI] Set vram state to: NORMAL_VRAM
[00:49]   [ComfyUI] Device: cuda:0 NVIDIA RTX A6000 : cudaMallocAsync
[00:49]   [ComfyUI] Using async weight offloading with 2 streams
[00:49]   [ComfyUI] Enabled pinned memory 45855.0
[00:49]   [ComfyUI] working around nvidia conv3d memory bug.
[00:51]   [ComfyUI] Using sage attention
[00:58]   [ComfyUI] Python version: 3.10.12 (main, Jan 26 2026, 14:55:28) [GCC 11.4.0]
[00:58]   [ComfyUI] ComfyUI version: 0.15.0
[00:59]   [ComfyUI] ****** User settings have been changed to be stored on the server instead of browser storage. ******
[00:59]   [ComfyUI] ****** For multi-user setups add the --multi-user CLI argument to enable multiple user profiles. ******
[00:59]   [ComfyUI] ComfyUI frontend version: 1.39.16
[00:59]   [ComfyUI] [Prompt Server] web root: /home/shadeform/workspaces/SAM3-0057/.venv/lib/python3.10/site-packages/comfyui_frontend_package/static
[01:03]   [ComfyUI] ComfyUI-Env-Manager v0.1.0 routes registered
[01:04]   [ComfyUI] 
[01:04]   [ComfyUI] Import times for custom nodes:
[01:04]   [ComfyUI]    0.0 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/websocket_image_save.py
[01:04]   [ComfyUI]    0.0 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-validate-endpoint
[01:04]   [ComfyUI]    0.0 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-Env-Manager
[01:04]   [ComfyUI]    0.0 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-SAM3
[01:04]   [ComfyUI]    0.2 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-Multiband
[01:04]   [ComfyUI]    0.2 seconds: /home/shadeform/workspaces/SAM3-0057/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite
[01:04]   [ComfyUI] 
[01:04]   [ComfyUI] Context impl SQLiteImpl.
[01:04]   [ComfyUI] Will assume non-transactional DDL.
[01:04]   [ComfyUI] Context impl SQLiteImpl.
[01:04]   [ComfyUI] Will assume non-transactional DDL.
[01:04]   [ComfyUI] Running upgrade  -> 0001_assets, Initial assets schema
[01:04]   [ComfyUI] Revision ID: 0001_assets
[01:04]   [ComfyUI] Revises: None
[01:04]   [ComfyUI] Create Date: 2025-12-10 00:00:00
[01:04]   [ComfyUI] Database upgraded from None to 0001_assets
[01:04]   [ComfyUI] Assets scan(roots=['models']) completed in 0.077s (created=11, skipped_existing=0, orphans_pruned=0, total_seen=11)
[01:04]   [ComfyUI] Starting server
[01:04]   [ComfyUI] 
[01:04]   [ComfyUI] To see the GUI go to: http://127.0.0.1:41891
[01:04] Server responding, waiting for nodes to load...
[01:24] Server is ready!
[01:24] Checking for import errors in server logs...
[01:24] No import errors detected
[01:25] Found 708 registered nodes
[01:25] [REGISTRATION] PASSED
[01:25] 
[01:25] [4/5] INSTANTIATION
[01:25] ----------------------------------------
[01:25] [DEBUG] server=<comfy_test.comfyui.server.ComfyUIServer object at 0x74b350f57c80>, server_url=None, api=<comfy_test.comfyui.api.ComfyUIAPI object at 0x74b34fcd3c20>
[01:25] Testing node constructors...
[01:33] All 15 node(s) instantiated successfully!
[01:33] [INSTANTIATION] PASSED
[01:33] 
[01:33] [5/5] EXECUTION
[01:33] ----------------------------------------
[01:33] [DEBUG] server=<comfy_test.comfyui.server.ComfyUIServer object at 0x74b350f57c80>, server_url=None, api=<comfy_test.comfyui.api.ComfyUIAPI object at 0x74b34fcd3c20>
[01:33] GPU runner - will execute 5 workflow(s)
[01:33] Running 5 workflow(s) (all with videos)...
[01:33] Starting headless browser...
[01:36]   GPU + Vulkan detected â€” using ANGLE/Vulkan rendering
[01:37] Capturing execution frames: image_seg_point.json
[01:37]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[01:37]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[01:39]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[01:39]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[01:39]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[01:39]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[01:39]   [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.
[01:39]   [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.
[01:39]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui.js" is deprecated and will be removed in v1.34.
[01:39]   [Console-warning] [ComfyUI Notice] "scripts/widgets.js" is an internal module, not part of the public API. Future updates may break this import.
[01:39]   [Console-warning] [ComfyUI Notice] "extensions/core/widgetInputs.js" is an internal module, not part of the public API. Future updates may break this import.
[01:39]   [Console-warning] [ComfyUI Notice] "scripts/utils.js" is an internal module, not part of the public API. Future updates may break this import.
[01:39]   [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
[01:41]   [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.
[01:41]   [ComfyUI] [DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.
[01:41]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/buttonGroup.js" is deprecated and will be removed in v1.34.
[01:41]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/button.js" is deprecated and will be removed in v1.34.
[01:47]   Frame 1 saved (frame_000.jpg, t=0.0s)
[01:48]   Validating workflow...
[01:48]   [ComfyUI] === /validate endpoint called ===
[01:48]   [ComfyUI] Received JSON with keys: ['prompt']
[01:48]   Queuing workflow for execution...
[01:48]   [ComfyUI] Prompt has 6 nodes
[01:48]   [ComfyUI]   Node 1: LoadImage
[01:48]   [ComfyUI]     Inputs: {"image": "example_image.jpg"}
[01:48]   [ComfyUI]   Node 15: SAM3PointCollector
[01:48]   [ComfyUI]     Inputs: {"points_store": "{\"positive\":[{\"x\":426.27735719657574,\"y\":321.42611685978835},{\"x\":417.13743597288953,\"y\":407.3413796907987},{\"x\":431.76130993078743,\"y\":549.9241563039649}],\"negative\"
[01:48]   [ComfyUI]   Node 24: SAM3Segmentation
[01:48]   [ComfyUI]     Inputs: {"refinement_iterations": 4, "use_multimask": false, "output_best_mask": false, "sam3_model": ["30", 0], "image": ["1", 0], "positive_points": ["15", 0]}
[01:48]   [ComfyUI]   Node 28: PreviewImage
[01:48]   [ComfyUI]     Inputs: {"images": ["24", 2]}
[01:48]   [ComfyUI]   Node 29: MaskPreview
[01:48]   [ComfyUI]     Inputs: {"mask": ["24", 0]}
[01:48]   [ComfyUI]   Node 30: LoadSAM3Model
[01:48]   [ComfyUI]     Inputs: {"precision": "auto", "attention": "auto", "compile": false}
[01:48]   [ComfyUI] Generated prompt_id: 3ea68f8c-ab02-4a8d-b790-94ae457651b8
[01:48]   [ComfyUI] Calling execution.validate_prompt()...
[01:48]   [ComfyUI] Validation result: valid=True
[01:48]   [ComfyUI] === Validation PASSED ===
[01:48]   [ComfyUI] got prompt
[01:48]   [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'
[01:48]   [ComfyUI] CACHE MISS - computing new result for key=d9204c29
[01:48]   [ComfyUI] Collected 3 positive, 0 negative points
[01:48]   [ComfyUI] Image dimensions: 1280x720
[01:48]   [ComfyUI]   Positive point: (426.3, 321.4) -> (0.333, 0.446)
[01:48]   [ComfyUI]   Positive point: (417.1, 407.3) -> (0.326, 0.566)
[01:48]   [ComfyUI]   Positive point: (431.8, 549.9) -> (0.337, 0.764)
[01:48]   [ComfyUI] Output: 3 positive, 0 negative
[01:48]   Node executed (1 total), capturing...
[01:49]   Frame 2 saved (frame_001.jpg, t=2.0s)
[01:49]   [capture-node] freeze=37ms shot=246ms unfreeze=7ms saved=True
[01:50]   [ComfyUI] Model not found at /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors, downloading from HuggingFace...
[01:50]   [ComfyUI] HTTP Request: HEAD https://huggingface.co/apozz/sam3-safetensors/resolve/main/sam3.safetensors "HTTP/1.1 302 Found"
[01:50]   [ComfyUI] HTTP Request: GET https://huggingface.co/api/models/apozz/sam3-safetensors/xet-read-token/e88da2ed02aded4006f4711ee6a9c75d5aa38d0c "HTTP/1.1 200 OK"
[01:55]   [capture-loop] iter=50 t=8.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=13
[02:02]   [capture-loop] iter=100 t=15.4s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=11
[02:06]   [ComfyUI] Model downloaded to: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[02:09]   [capture-loop] iter=150 t=21.9s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=3
[02:09]   [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[02:09]   [ComfyUI] Sam3VideoPredictor using device: cuda:0
[02:09]   [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.
[02:09]   [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16
[02:09]   [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[02:09]   [ComfyUI] Added 309 keys for detector.inst_interactive_predictor
[02:09]   [ComfyUI] Model ready (1756.7 MB)
[02:09]   [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity
[02:09]   [ComfyUI] Using click-based interactive segmentation
[02:09]   [ComfyUI] Image size: (1280, 720)
[02:09]   [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0
[02:09]   [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[02:09]   [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[02:09]   [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[02:10]   Frame 3 saved (frame_002.jpg, t=23.3s)
[02:10]   [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16
[02:24]   [capture-periodic] freeze=5ms shot=397ms unfreeze=7ms saved=True
[02:25]   [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]
[02:25]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]
[02:25]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]
[02:25]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]
[02:25]   [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']
[02:25]   [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031
[02:25]   [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500
[02:25]   [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000
[02:25]   [ComfyUI] sam2_backbone_out is available
[02:25]   [ComfyUI] Added 3 positive points
[02:25]   [ComfyUI] Points: 3
[02:25]   [ComfyUI]   Coords: [[426.27735719657574, 321.42611685978835], [417.13743597288953, 407.3413796907987], [431.76130993078743, 549.9241563039649]]
[02:25]   [ComfyUI]   Labels: [1, 1, 1]
[02:25]   [ComfyUI] Refinement 1/4, best score: 0.9648
[02:25]   [ComfyUI] Refinement 2/4, best score: 0.9688
[02:25]   [ComfyUI] Refinement 3/4, best score: 0.9688
[02:25]   [ComfyUI] Refinement 4/4, best score: 0.9688
[02:25]   [ComfyUI] Prediction returned 1 masks
[02:25]   [ComfyUI]   Mask shape: (1, 720, 1280)
[02:25]   [ComfyUI]   Low-res shape: (1, 288, 288)
[02:25]   [ComfyUI]   Scores: [0.96875]
[02:25]   [ComfyUI] Outputting all 1 mask candidates
[02:25]   Node executed (3 total), capturing...
[02:25]   [ComfyUI] Segmentation complete
[02:25]   [ComfyUI] Prompt executed in 25.65 seconds
[02:26]   Frame 4 saved (frame_003.jpg, t=38.6s)
[02:26]   [capture-node] freeze=10ms shot=258ms unfreeze=0ms saved=True
[02:26]   Execution complete (t=38.6s)
[02:26]   Captured 4 unique frames over 39.11s
[02:26]   [debug] iframes: 0
[02:26]   [timing] trigger_3d_previews: 0.0s
[02:29]   Saved high-quality screenshot: image_seg_point_executed.png
[02:30]   [timing] final_screenshot: 1.9s
[02:30] Capturing execution frames: image_seg_text.json
[02:31]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:31]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:31]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:32]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:32]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:32]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:32]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui.js" is deprecated and will be removed in v1.34.
[02:32]   [Console-warning] [ComfyUI Notice] "scripts/widgets.js" is an internal module, not part of the public API. Future updates may break this import.
[02:32]   [Console-warning] [ComfyUI Notice] "extensions/core/widgetInputs.js" is an internal module, not part of the public API. Future updates may break this import.
[02:32]   [Console-warning] [ComfyUI Notice] "scripts/utils.js" is an internal module, not part of the public API. Future updates may break this import.
[02:32]   [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
[02:33]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/buttonGroup.js" is deprecated and will be removed in v1.34.
[02:33]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/button.js" is deprecated and will be removed in v1.34.
[02:38]   Frame 1 saved (frame_000.jpg, t=0.0s)
[02:38]   Validating workflow...
[02:38]   [ComfyUI] === /validate endpoint called ===
[02:38]   [ComfyUI] Received JSON with keys: ['prompt']
[02:38]   [ComfyUI] Prompt has 5 nodes
[02:38]   Queuing workflow for execution...
[02:38]   [ComfyUI]   Node 1: LoadImage
[02:38]   [ComfyUI]     Inputs: {"image": "example_image.jpg"}
[02:38]   [ComfyUI]   Node 3: PreviewImage
[02:38]   [ComfyUI]     Inputs: {"images": ["13", 1]}
[02:38]   [ComfyUI]   Node 4: MaskPreview
[02:38]   [ComfyUI]     Inputs: {"mask": ["13", 0]}
[02:38]   [ComfyUI]   Node 12: LoadSAM3Model
[02:38]   [ComfyUI]     Inputs: {"precision": "auto", "attention": "auto", "compile": false}
[02:38]   [ComfyUI]   Node 13: SAM3Grounding
[02:38]   [ComfyUI]     Inputs: {"confidence_threshold": 0.2, "text_prompt": "person", "max_detections": -1, "sam3_model": ["12", 0], "image": ["1", 0]}
[02:38]   [ComfyUI] Generated prompt_id: d5d4d34f-2bf2-460e-b37d-9d432bc35dd4
[02:38]   [ComfyUI] Calling execution.validate_prompt()...
[02:38]   [ComfyUI] Validation result: valid=True
[02:38]   [ComfyUI] === Validation PASSED ===
[02:38]   [ComfyUI] got prompt
[02:38]   [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[02:38]   [ComfyUI] Sam3VideoPredictor using device: cuda:0
[02:38]   [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.
[02:40]   [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16
[02:40]   [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[02:40]   [ComfyUI] Added 309 keys for detector.inst_interactive_predictor
[02:41]   Frame 2 saved (frame_001.jpg, t=2.4s)
[02:41]   [capture-periodic] freeze=3ms shot=165ms unfreeze=15ms saved=True
[02:42]   [ComfyUI] Model ready (1756.7 MB)
[02:42]   [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity
[02:42]   [ComfyUI] Running text-based detection
[02:42]   [ComfyUI]   Text prompt: 'person'
[02:42]   [ComfyUI] Confidence threshold: 0.2
[02:42]   [ComfyUI] Image size: (1280, 720)
[02:42]   [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=1.0000, device=cuda:0
[02:42]   [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[02:42]   [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[02:42]   [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[02:42]   [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16
[02:42]   [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]
[02:42]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]
[02:42]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]
[02:42]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-5.7188 max=5.5000   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]
[02:42]   [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']
[02:42]   [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2412, max=0.2031
[02:42]   [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-10.8750, max=11.7500
[02:42]   [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-5.7188, max=5.5000
[02:42]   [ComfyUI] Adding text prompt...
[02:42]   [ComfyUI] [DEBUG] set_text_prompt: prompt='person', device=cuda:0
[02:42]   [ComfyUI] [DEBUG] language_features: shape=torch.Size([32, 1, 256]), dtype=torch.bfloat16, min=-3.5469, max=4.5000, mean=0.0557
[02:42]   [ComfyUI] [DEBUG] language_mask: shape=torch.Size([1, 32]), dtype=torch.bool, num_valid=3, num_padding=29
[02:42]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[02:42]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[02:42]   [ComfyUI] Encoder.forward IN:   src=[torch.bfloat16 [5184, 1, 256]]   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250
[02:43]   Frame 3 saved (frame_002.jpg, t=4.7s)
[02:43]   [capture-periodic] freeze=5ms shot=224ms unfreeze=7ms saved=True
[02:44]   [ComfyUI] Encoder.forward OUT:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250
[02:44]   [ComfyUI] _run_encoder output:   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000
[02:44]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000
[02:44]   [ComfyUI] _run_decoder inputs:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pos_embed=torch.bfloat16 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[02:44]   [ComfyUI] Decoder.forward IN:   tgt=torch.bfloat16 [200, 1, 256] min=-0.6758 max=0.5938   memory=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   memory_text=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250
[02:44]   [ComfyUI] Decoder.forward OUT:   output=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   ref_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   presence=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336
[02:44]   [ComfyUI] _run_decoder output:   hs=torch.bfloat16 [6, 200, 1, 256] min=-6.7500 max=6.8125   reference_boxes=torch.bfloat16 [6, 200, 1, 4] min=0.0089 max=0.9805   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336
[02:44]   [ComfyUI] _update_scores_and_boxes:   hs=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   prompt=torch.bfloat16 [33, 1, 256] min=-6.4062 max=10.1250   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[02:44]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188
[02:44]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.bfloat16 [6, 1, 200, 1] min=-9.6250 max=2.7188   dec_presence_out=torch.bfloat16 [6, 1, 1] min=-1.0859 max=-0.9336
[02:44]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.bfloat16 [6, 1, 200, 1] min=-6.9062 max=-1.0547
[02:44]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844
[02:44]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]   obj_queries=torch.bfloat16 [6, 1, 200, 256] min=-6.7500 max=6.8125   encoder_hidden_states=torch.bfloat16 [5184, 1, 256] min=-20.0000 max=11.4375
[02:44]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   semantic_seg=torch.bfloat16 [1, 1, 288, 288] min=-35.5000 max=13.5000   presence_logit=None
[02:44]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.bfloat16 [1, 200, 1] min=-6.9062 max=-1.1406   pred_masks=torch.bfloat16 [1, 200, 288, 288] min=-123.5000 max=13.1875   pred_boxes=torch.bfloat16 [1, 200, 4] min=0.0094 max=0.9844
[02:44]   [ComfyUI] [DEBUG] forward_grounding output keys: ['encoder_hidden_states', 'prev_encoder_out', 'presence_feats', 'queries', 'presence_logit_dec', 'pred_logits', 'pred_boxes', 'pred_boxes_xyxy', 'pred_masks', 'semantic_seg', 'presence_logit']
[02:44]   [ComfyUI] [DEBUG] pred_logits shape: torch.Size([1, 200, 1]), min: -6.9062, max: -1.1406
[02:44]   [ComfyUI] [DEBUG] pred_boxes shape: torch.Size([1, 200, 4])
[02:44]   [ComfyUI] [DEBUG] pred_masks shape: torch.Size([1, 200, 288, 288])
[02:44]   [ComfyUI] [DEBUG] presence_logit_dec: torch.Size([1, 1]), val=[-1.0546875], sigmoid=[0.2578125]
[02:44]   [ComfyUI] [DEBUG] out_probs (joint_box_scores, no double presence): min=0.0010, max=0.2422
[02:44]   [ComfyUI] [DEBUG] confidence_threshold: 0.2
[02:44]   [ComfyUI] [DEBUG] detections above threshold: 6 / 200
[02:44]   [ComfyUI] [DEBUG] top-10 probs: ['0.2422', '0.2383', '0.2363', '0.2354', '0.2354', '0.2295', '0.0233', '0.0192', '0.0188', '0.0186']
[02:44]   [ComfyUI] [DEBUG] after threshold: 6 detections
[02:44]   [ComfyUI] [DEBUG] after NMS (iou_thresh=0.5): 6 detections (suppressed 0)
[02:44]   [ComfyUI] Found 6 detections above threshold 0.2
[02:44]   [ComfyUI] Sorting 6 detections by score...
[02:44]   [ComfyUI] Creating visualization...
[02:44]   [ComfyUI] Detection complete: 6 masks
[02:45]   [capture-loop] iter=50 t=7.0s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=7
[02:45]   [ComfyUI] Prompt executed in 6.90 seconds
[02:46]   Frame 4 saved (frame_003.jpg, t=7.0s)
[02:46]   [capture-periodic] freeze=23ms shot=191ms unfreeze=5ms saved=True
[02:46]   Node executed (2 total), capturing...
[02:46]   Frame 5 saved (frame_004.jpg, t=7.8s)
[02:46]   [capture-node] freeze=33ms shot=247ms unfreeze=11ms saved=True
[02:46]   Execution complete (t=8.2s)
[02:46]   Captured 5 unique frames over 8.26s
[02:46]   [debug] iframes: 0
[02:46]   [timing] trigger_3d_previews: 0.0s
[02:50]   Saved high-quality screenshot: image_seg_text_executed.png
[02:50]   [timing] final_screenshot: 1.5s
[02:50] Capturing execution frames: scene_seg.json
[02:50]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:50]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:51]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:52]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:53]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:53]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[02:53]   [Console-warning] [ComfyUI Notice] "extensions/core/widgetInputs.js" is an internal module, not part of the public API. Future updates may break this import.
[02:53]   [Console-warning] [ComfyUI Notice] "scripts/utils.js" is an internal module, not part of the public API. Future updates may break this import.
[02:53]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui.js" is deprecated and will be removed in v1.34.
[02:53]   [Console-warning] [ComfyUI Notice] "scripts/widgets.js" is an internal module, not part of the public API. Future updates may break this import.
[02:53]   [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
[02:54]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/buttonGroup.js" is deprecated and will be removed in v1.34.
[02:54]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/button.js" is deprecated and will be removed in v1.34.
[02:59]   Frame 1 saved (frame_000.jpg, t=0.0s)
[03:00]   Validating workflow...
[03:00]   [ComfyUI] === /validate endpoint called ===
[03:00]   [ComfyUI] Received JSON with keys: ['prompt']
[03:00]   Queuing workflow for execution...
[03:00]   [ComfyUI] Prompt has 10 nodes
[03:00]   [ComfyUI]   Node 1: LoadImage
[03:00]   [ComfyUI]     Inputs: {"image": "image.png"}
[03:00]   [ComfyUI]   Node 3: PreviewImage
[03:00]   [ComfyUI]     Inputs: {"images": ["21", 1]}
[03:00]   [ComfyUI]   Node 4: MaskPreview
[03:00]   [ComfyUI]     Inputs: {"mask": ["21", 0]}
[03:00]   [ComfyUI]   Node 12: LoadSAM3Model
[03:00]   [ComfyUI]     Inputs: {"precision": "auto", "attention": "auto", "compile": false}
[03:00]   [ComfyUI]   Node 20: SAM3MultiRegionCollector
[03:00]   [ComfyUI]     Inputs: {"multi_prompts_store": "[{\"positive_points\":[{\"x\":5052.74953932266,\"y\":2847.0600693869637},{\"x\":4932.510591392486,\"y\":2953.9413227753366},{\"x\":4718.752461738845,\"y\":2967.301479448883},{
[03:00]   [ComfyUI]   Node 21: SAM3MultipromptSegmentation
[03:00]   [ComfyUI]     Inputs: {"refinement_iterations": 2, "use_multimask": false, "sam3_model": ["12", 0], "image": ["1", 0], "multi_prompts": ["20", 0]}
[03:00]   [ComfyUI]   Node 22: MultibandFromBatch
[03:00]   [ComfyUI]     Inputs: {"images": ["1", 0], "masks": ["21", 0]}
[03:00]   [ComfyUI]   Node 23: MultibandSave
[03:00]   [ComfyUI]     Inputs: {"file_path": "output/multiband", "format": "npz", "multiband": ["26", 0]}
[03:00]   [ComfyUI]   Node 24: MultibandPreview
[03:00]   [ComfyUI]     Inputs: {"channel_index": 0, "multiband": ["26", 0]}
[03:00]   [ComfyUI]   Node 26: MultibandResize
[03:00]   [ComfyUI]     Inputs: {"upscale_method": "nearest-exact", "width": 900, "height": 600, "crop": "center", "multiband": ["22", 0]}
[03:00]   [ComfyUI] Generated prompt_id: 76fb6555-c11a-48fc-8fb7-e6866b54dae1
[03:00]   [ComfyUI] Calling execution.validate_prompt()...
[03:00]   [ComfyUI] Validation result: valid=True
[03:00]   [ComfyUI] === Validation PASSED ===
[03:00]   [ComfyUI] got prompt
[03:00]   [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'
[03:02]   Frame 2 saved (frame_001.jpg, t=3.0s)
[03:04]   [ComfyUI] CACHE MISS - computing new result for key=35316a77
[03:04]   [capture-periodic] freeze=4ms shot=179ms unfreeze=6ms saved=True
[03:06]   [ComfyUI] Image dimensions: 6720x4480
[03:06]   [ComfyUI] Processing 7 prompt regions
[03:06]   [ComfyUI]   Prompt 0: 10 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI]   Prompt 1: 7 pos pts, 16 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI]   Prompt 2: 7 pos pts, 14 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI]   Prompt 3: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI]   Prompt 4: 1 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI]   Prompt 5: 13 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI]   Prompt 6: 6 pos pts, 0 neg pts, 1 pos boxes, 0 neg boxes
[03:06]   [ComfyUI] Output: 7 non-empty prompts
[03:06]   [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[03:06]   [ComfyUI] Sam3VideoPredictor using device: cuda:0
[03:06]   [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.
[03:06]   Node executed (1 total), capturing...
[03:07]   [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16
[03:07]   [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[03:07]   [ComfyUI] Added 309 keys for detector.inst_interactive_predictor
[03:07]   Frame 3 saved (frame_002.jpg, t=7.8s)
[03:07]   [capture-node] freeze=110ms shot=406ms unfreeze=8ms saved=True
[03:08]   [ComfyUI] Model ready (1756.7 MB)
[03:08]   [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity
[03:09]   [ComfyUI] Image size: (6720, 4480)
[03:10]   Frame 4 saved (frame_003.jpg, t=10.5s)
[03:10]   [ComfyUI] Processing 7 prompt regions
[03:10]   [capture-periodic] freeze=4ms shot=204ms unfreeze=5ms saved=True
[03:10]   [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0
[03:10]   [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
[03:10]   [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
[03:10]   [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
[03:10]   [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16
[03:10]   [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]
[03:10]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]
[03:10]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]
[03:10]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]
[03:10]   [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']
[03:10]   [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539
[03:10]   [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375
[03:10]   [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625
[03:10]   [ComfyUI] Processing prompt region 1/7
[03:10]   [ComfyUI]   Points: 10, Box: Yes
[03:10]   [ComfyUI]   Mask score: 0.9805
[03:10]   [ComfyUI] Processing prompt region 2/7
[03:10]   [ComfyUI]   Points: 23, Box: Yes
[03:11]   [ComfyUI]   Mask score: 0.9414
[03:11]   [ComfyUI] Processing prompt region 3/7
[03:11]   [ComfyUI]   Points: 21, Box: Yes
[03:11]   [capture-loop] iter=50 t=12.1s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5
[03:11]   [ComfyUI]   Mask score: 0.9023
[03:11]   [ComfyUI] Processing prompt region 4/7
[03:11]   [ComfyUI]   Points: 1, Box: Yes
[03:12]   [ComfyUI]   Mask score: 0.9766
[03:12]   [ComfyUI] Processing prompt region 5/7
[03:12]   [ComfyUI]   Points: 1, Box: Yes
[03:12]   [ComfyUI]   Mask score: 0.9844
[03:12]   [ComfyUI] Processing prompt region 6/7
[03:12]   [ComfyUI]   Points: 13, Box: Yes
[03:13]   [ComfyUI]   Mask score: 0.9883
[03:13]   [ComfyUI] Processing prompt region 7/7
[03:13]   [ComfyUI]   Points: 6, Box: Yes
[03:13]   [ComfyUI]   Mask score: 0.9688
[03:14]   [ComfyUI] Generated 7 masks
[03:18]   [capture-loop] iter=100 t=18.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4
[03:24]   [capture-loop] iter=150 t=24.8s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=5
[03:30]   [capture-loop] iter=200 t=31.0s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=8
[03:32]   Frame 5 saved (frame_004.jpg, t=33.3s)
[03:32]   [capture-periodic] freeze=4ms shot=212ms unfreeze=10ms saved=True
[03:36]   [capture-loop] iter=250 t=37.2s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4
[03:37]   Node executed (2 total), capturing...
[03:39]   Frame 6 saved (frame_005.jpg, t=38.2s)
[03:39]   [capture-node] freeze=247ms shot=1271ms unfreeze=9ms saved=True
[03:44]   [capture-loop] iter=300 t=45.6s state={'complete': False, 'error': None, 'executedCount': 2, 'wsState': 1} eval_ms=5
[03:48]   Node executed (3 total), capturing...
[03:48]   Frame 7 saved (frame_006.jpg, t=48.9s)
[03:48]   [capture-node] freeze=4ms shot=204ms unfreeze=7ms saved=True
[03:49]   Node executed (4 total), capturing...
[03:50]   Frame 8 saved (frame_007.jpg, t=50.6s)
[03:50]   [capture-node] freeze=4ms shot=243ms unfreeze=11ms saved=True
[03:50]   [ComfyUI] Prompt executed in 50.20 seconds
[03:50]   Execution complete (t=51.1s)
[03:50]   Captured 8 unique frames over 51.13s
[03:50]   [debug] iframes: 0
[03:50]   [timing] trigger_3d_previews: 0.0s
[03:55]   Saved high-quality screenshot: scene_seg_executed.png
[03:55]   [timing] final_screenshot: 2.4s
[03:55] Capturing execution frames: scene_seg_interactive.json
[03:56]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[03:56]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[03:57]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[03:57]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[03:57]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[03:57]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[03:57]   [Console-warning] [ComfyUI Notice] "extensions/core/widgetInputs.js" is an internal module, not part of the public API. Future updates may break this import.
[03:57]   [Console-warning] [ComfyUI Notice] "scripts/utils.js" is an internal module, not part of the public API. Future updates may break this import.
[03:57]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui.js" is deprecated and will be removed in v1.34.
[03:57]   [Console-warning] [ComfyUI Notice] "scripts/widgets.js" is an internal module, not part of the public API. Future updates may break this import.
[03:57]   [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
[03:59]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/buttonGroup.js" is deprecated and will be removed in v1.34.
[03:59]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/button.js" is deprecated and will be removed in v1.34.
[04:05]   Frame 1 saved (frame_000.jpg, t=0.0s)
[04:05]   Validating workflow...
[04:05]   [ComfyUI] === /validate endpoint called ===
[04:05]   [ComfyUI] Received JSON with keys: ['prompt']
[04:05]   [ComfyUI] Prompt has 4 nodes
[04:05]   [ComfyUI]   Node 1: LoadImage
[04:05]   [ComfyUI]     Inputs: {"image": "image.png"}
[04:05]   [ComfyUI]   Node 4: MaskPreview
[04:05]   [ComfyUI]     Inputs: {"mask": ["25", 0]}
[04:05]   [ComfyUI]   Node 12: LoadSAM3Model
[04:05]   [ComfyUI]     Inputs: {"precision": "auto", "attention": "auto", "compile": false}
[04:05]   [ComfyUI]   Node 25: SAM3InteractiveCollector
[04:05]   [ComfyUI]     Inputs: {"multi_prompts_store": "[{\"positive_points\":[{\"x\":3346.704486138097,\"y\":2681.6412520604563},{\"x\":3353.9719078740486,\"y\":2332.7978245699082}],\"negative_points\":[],\"positive_boxes\":[],\"n
[04:05]   [ComfyUI] Generated prompt_id: 6b47d7f2-15f8-4b23-9a61-1401a5241ed2
[04:05]   [ComfyUI] Calling execution.validate_prompt()...
[04:05]   [ComfyUI] Validation result: valid=True
[04:05]   [ComfyUI] === Validation PASSED ===
[04:05]   Queuing workflow for execution...
[04:05]   [ComfyUI] got prompt
[04:05]   [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'
[04:06]   [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[04:06]   [ComfyUI] Sam3VideoPredictor using device: cuda:0
[04:06]   [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.
[04:07]   [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16
[04:07]   [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[04:08]   [ComfyUI] Added 309 keys for detector.inst_interactive_predictor
[04:08]   Frame 2 saved (frame_001.jpg, t=3.0s)
[04:08]   [capture-periodic] freeze=52ms shot=189ms unfreeze=6ms saved=True
[04:09]   [ComfyUI] Model ready (1756.7 MB)
[04:09]   [ComfyUI] Requested to load Sam3VideoInferenceWithInstanceInteractivity
[04:10]   [ComfyUI] [DEBUG] set_image: input shape=torch.Size([1, 3, 1008, 1008]), dtype=torch.bfloat16, min=-1.0000, max=0.9531, device=cuda:0
[04:10]   [ComfyUI] Backbone.forward_image IN:   samples=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
[04:10]   [ComfyUI] FPN_Neck.forward IN:   input=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
[04:10]   [ComfyUI] ViT.forward IN:   x=torch.bfloat16 [1, 3, 1008, 1008] min=-1.0000 max=0.9531
[04:10]   [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16
[04:10]   [ComfyUI] ViT.forward OUT:   features=[torch.bfloat16 [1, 1024, 72, 72]]
[04:10]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.bfloat16 [1, 1024, 72, 72]]
[04:10]   Frame 3 saved (frame_002.jpg, t=5.3s)
[04:10]   [capture-periodic] freeze=6ms shot=191ms unfreeze=16ms saved=True
[04:10]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]   sam3_pos=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72], torch.bfloat16 [1, 256, 36, 36]]
[04:10]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.bfloat16 [1, 256, 72, 72] min=-6.0000 max=6.0625   backbone_fpn=[torch.bfloat16 [1, 256, 288, 288], torch.bfloat16 [1, 256, 144, 144], torch.bfloat16 [1, 256, 72, 72]]
[04:10]   [ComfyUI] [DEBUG] set_image: backbone_out keys: ['vision_features', 'vision_pos_enc', 'backbone_fpn', 'sam2_backbone_out']
[04:10]   [ComfyUI] [DEBUG]   backbone_fpn[0]: shape=torch.Size([1, 256, 288, 288]), dtype=torch.bfloat16, min=-0.2930, max=0.2539
[04:10]   [ComfyUI] [DEBUG]   backbone_fpn[1]: shape=torch.Size([1, 256, 144, 144]), dtype=torch.bfloat16, min=-11.8750, max=12.4375
[04:10]   [ComfyUI] [DEBUG]   backbone_fpn[2]: shape=torch.Size([1, 256, 72, 72]), dtype=torch.bfloat16, min=-6.0000, max=6.0625
[04:12]   [capture-loop] iter=50 t=7.3s state={'complete': False, 'error': None, 'executedCount': 0, 'wsState': 1} eval_ms=13
[04:12]   Frame 4 saved (frame_003.jpg, t=7.8s)
[04:12]   [capture-periodic] freeze=5ms shot=153ms unfreeze=162ms saved=True
[04:15]   Frame 5 saved (frame_004.jpg, t=10.2s)
[04:15]   [capture-periodic] freeze=3ms shot=151ms unfreeze=8ms saved=True
[04:18]   Node executed (1 total), capturing...
[04:18]   [ComfyUI] Prompt executed in 12.99 seconds
[04:18]   Frame 6 saved (frame_005.jpg, t=13.8s)
[04:18]   [capture-node] freeze=5ms shot=190ms unfreeze=19ms saved=True
[04:18]   Node executed (2 total), capturing...
[04:20]   Frame 7 saved (frame_006.jpg, t=14.3s)
[04:20]   [capture-node] freeze=224ms shot=1140ms unfreeze=7ms saved=True
[04:20]   Execution complete (t=16.0s)
[04:20]   Captured 7 unique frames over 15.99s
[04:20]   [debug] iframes: 0
[04:20]   [timing] trigger_3d_previews: 0.0s
[04:24]   Saved high-quality screenshot: scene_seg_interactive_executed.png
[04:24]   [timing] final_screenshot: 1.4s
[04:24] Capturing execution frames: video_point_prompt.json
[04:24]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[04:24]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[04:24]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[04:25]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[04:25]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[04:25]   [Console-error] Failed to load resource: the server responded with a status of 404 (Not Found)
[04:25]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui.js" is deprecated and will be removed in v1.34.
[04:25]   [Console-warning] [ComfyUI Notice] "scripts/widgets.js" is an internal module, not part of the public API. Future updates may break this import.
[04:25]   [Console-warning] [ComfyUI Notice] "extensions/core/widgetInputs.js" is an internal module, not part of the public API. Future updates may break this import.
[04:25]   [Console-warning] [ComfyUI Notice] "scripts/utils.js" is an internal module, not part of the public API. Future updates may break this import.
[04:25]   [Console-warning] [MaskEditor] ComfyApp.open_maskeditor is deprecated. Plugins should migrate to using the command system or direct node context menu integration.
[04:27]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/buttonGroup.js" is deprecated and will be removed in v1.34.
[04:27]   [Console-warning] [ComfyUI Deprecated] Importing from "scripts/ui/components/button.js" is deprecated and will be removed in v1.34.
[04:33]   Frame 1 saved (frame_000.jpg, t=0.0s)
[04:33]   Validating workflow...
[04:33]   [ComfyUI] === /validate endpoint called ===
[04:33]   [ComfyUI] Received JSON with keys: ['prompt']
[04:33]   [ComfyUI] Prompt has 11 nodes
[04:33]   Queuing workflow for execution...
[04:33]   [ComfyUI]   Node 9: VHS_LoadVideo
[04:33]   [ComfyUI]     Inputs: {"video": "bedroom.mp4", "force_rate": 0, "custom_width": 0, "custom_height": 0, "frame_load_cap": 30, "skip_first_frames": 0, "select_every_nth": 1, "format": "AnimateDiff"}
[04:33]   [ComfyUI]   Node 13: CreateVideo
[04:33]   [ComfyUI]     Inputs: {"fps": 30, "images": ["14", 0]}
[04:33]   [ComfyUI]   Node 14: MaskToImage
[04:33]   [ComfyUI]     Inputs: {"mask": ["21", 0]}
[04:33]   [ComfyUI]   Node 15: SaveVideo
[04:33]   [ComfyUI]     Inputs: {"filename_prefix": "video/ComfyUI", "format": "auto", "codec": "auto", "video": ["13", 0]}
[04:33]   [ComfyUI]   Node 21: SAM3VideoOutput
[04:33]   [ComfyUI]     Inputs: {"obj_id": 0, "plot_all_masks": true, "masks": ["32", 0], "video_state": ["32", 2], "scores": ["32", 1]}
[04:33]   [ComfyUI]   Node 24: CreateVideo
[04:33]   [ComfyUI]     Inputs: {"fps": 30, "images": ["21", 2]}
[04:33]   [ComfyUI]   Node 25: SaveVideo
[04:33]   [ComfyUI]     Inputs: {"filename_prefix": "video/ComfyUI", "format": "auto", "codec": "auto", "video": ["24", 0]}
[04:33]   [ComfyUI]   Node 27: SAM3VideoSegmentation
[04:33]   [ComfyUI]     Inputs: {"prompt_mode": "point", "frame_idx": 0.3, "score_threshold": 0.3, "video_frames": ["9", 0], "positive_points": ["28", 0]}
[04:33]   [ComfyUI]   Node 28: SAM3PointCollector
[04:33]   [ComfyUI]     Inputs: {"points_store": "{\"positive\":[{\"x\":365.8296849641195,\"y\":82.1138596932428},{\"x\":389.5481601701001,\"y\":179.95494578458334},{\"x\":413.26663537608084,\"y\":52.465045726169905}],\"negative\":[
[04:33]   [ComfyUI]   Node 30: LoadSAM3Model
[04:33]   [ComfyUI]     Inputs: {"precision": "auto", "attention": "auto", "compile": false}
[04:33]   [ComfyUI]   Node 32: SAM3Propagate
[04:33]   [ComfyUI]     Inputs: {"start_frame": 0, "end_frame": -1, "direction": "forward", "sam3_model": ["30", 0], "video_state": ["27", 0]}
[04:33]   [ComfyUI] Generated prompt_id: 50206a41-7fc4-4093-8763-02701e505678
[04:33]   [ComfyUI] Calling execution.validate_prompt()...
[04:33]   [ComfyUI] Validation result: valid=True
[04:33]   [ComfyUI] === Validation PASSED ===
[04:33]   [ComfyUI] got prompt
[04:33]   [ComfyUI] WARNING: 'NoneType' object has no attribute 'session_uuid'
[04:33]   [ComfyUI] IS_CHANGED SAM3Propagate: video_state id=96667792430048, session=None
[04:33]   [ComfyUI] IS_CHANGED SAM3Propagate: returning (96667792430048, 0, -1, 'forward')
[04:33]   [ComfyUI] IS_CHANGED SAM3VideoSegmentation: video_hash=9356dabdc8862dff08a9ab9d174121c1, prompt_mode=point
[04:33]   [ComfyUI] IS_CHANGED SAM3VideoSegmentation: positive_points=None
[04:33]   [ComfyUI] IS_CHANGED SAM3VideoSegmentation: negative_points=None
[04:33]   [ComfyUI] IS_CHANGED SAM3VideoSegmentation: returning hash=4255372223738472285
[04:33]   [ComfyUI] WARNING: 'NoneType' object has no attribute 'shape'
[04:35]   [ComfyUI] CACHE MISS - computing new result for key=d7f60d60
[04:35]   [ComfyUI] Collected 3 positive, 0 negative points
[04:35]   [ComfyUI] Image dimensions: 960x544
[04:35]   [ComfyUI]   Positive point: (365.8, 82.1) -> (0.381, 0.151)
[04:35]   [ComfyUI]   Positive point: (389.5, 180.0) -> (0.406, 0.331)
[04:35]   [ComfyUI]   Positive point: (413.3, 52.5) -> (0.430, 0.096)
[04:35]   [ComfyUI] Output: 3 positive, 0 negative
[04:35]   [ComfyUI] CACHE MISS - computing new video_state for key=911ad089
[04:35]   [ComfyUI] [MEM] Before video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)
[04:35]   [ComfyUI] Saving 30 frames to /tmp/sam3_e347f3b6_8uc25nxo
[04:35]   Node executed (1 total), capturing...
[04:35]   [ComfyUI] Frames saved successfully
[04:35]   [ComfyUI] Initialized session e347f3b6
[04:35]   [ComfyUI] Frames: 30, Size: 960x544
[04:35]   [ComfyUI] Prompt mode: point
[04:35]   [ComfyUI] Added point prompt: obj=1, positive=3, negative=0
[04:35]   [ComfyUI] Total prompts: 1
[04:35]   [ComfyUI] [MEM] After video segmentation: VRAM 0.28GB alloc / 0.53GB reserved | RAM: 6.16GB (process), 22.2/47.1GB (system)
[04:35]   [ComfyUI] Loading model from: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[04:35]   [ComfyUI] Sam3VideoPredictor using device: cuda:0
[04:35]   [ComfyUI] SageAttention is not compatible with SAM3 (relative position bias modifies Q/K dimensions). Using attention_flash instead.
[04:35]   Frame 2 saved (frame_001.jpg, t=2.4s)
[04:35]   [capture-node] freeze=4ms shot=228ms unfreeze=9ms saved=True
[04:36]   [ComfyUI] setting max_num_objects=10000 and num_obj_for_compile=16
[04:36]   [ComfyUI] Loading checkpoint: /home/shadeform/workspaces/SAM3-0057/ComfyUI/models/sam3/sam3.safetensors
[04:36]   [ComfyUI] Added 309 keys for detector.inst_interactive_predictor
[04:38]   [ComfyUI] Model ready (1756.7 MB)
[04:38]   [ComfyUI] Propagate CACHE MISS - running propagation for session=e347f3b6
[04:38]   [ComfyUI] Starting propagation: frames 0 to end
[04:38]   Frame 3 saved (frame_002.jpg, t=4.8s)
[04:38]   [ComfyUI] Prompts: 1
[04:38]   [capture-periodic] freeze=3ms shot=180ms unfreeze=6ms saved=True
[04:38]   [ComfyUI] [MEM] Before propagation start: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)
[04:38]   [ComfyUI] [MEM] Before reconstruction: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)
[04:38]   [ComfyUI] Reconstructing inference state for e347f3b6
[04:38]   [ComfyUI] [MEM] Before start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)
[04:38]   [ComfyUI] [MEM] Before init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.43GB (process), 22.3/47.1GB (system)
[04:38]   [ComfyUI] LazyLoader initialized: 30 frames, max_cached=64, offload_to_cpu=True
[04:38]   [ComfyUI] [MEM] After init_state: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)
[04:38]   [ComfyUI] Active sessions in _ALL_INFERENCE_STATES: 1
[04:38]   [ComfyUI] [MEM] After start_session: VRAM 2.00GB alloc / 3.56GB reserved | RAM: 6.44GB (process), 22.3/47.1GB (system)
[04:38]   [ComfyUI] Applying point prompt: frame=0, obj=1
[04:38]   [ComfyUI] Points to model: [[0.38107258850429115, 0.15094459502434338], [0.405779333510521, 0.3307995326922488], [0.43048607851675086, 0.09644309876134173]], labels: [1, 1, 1]
[04:38]   [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] attention backend: attention_flash | dtype: torch.bfloat16
[04:38]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:38]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:38]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:38]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8435 max=5.0555   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:38]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:38]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:38]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958
[04:38]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958
[04:38]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:38]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   memory_text=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958
[04:38]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   presence=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433
[04:38]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8378 max=5.2344   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0097 max=0.9882   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433
[04:38]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   prompt=torch.float32 [33, 1, 256] min=-6.3182 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:38]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103
[04:38]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4571 max=0.9103   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0779 max=-10.7433
[04:38]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:38]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893
[04:38]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8378 max=5.2344   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5106 max=11.1368
[04:38]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0381 max=10.9215   presence_logit=None
[04:38]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6211 max=11.4404   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9893
[04:38]   [ComfyUI] Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:38]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:38]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:38]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:39]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0789 max=5.6223   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:39]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:39]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:39]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952
[04:39]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952
[04:39]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:39]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:39]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:39]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   memory_text=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952
[04:39]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606
[04:39]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8766 max=5.2941   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606
[04:39]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   prompt=torch.float32 [33, 1, 256] min=-6.3202 max=10.1952   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:39]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455
[04:39]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4874 max=0.8455   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1032 max=-10.7606
[04:39]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:39]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894
[04:39]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8766 max=5.2941   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7887 max=11.2994
[04:39]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   semantic_seg=torch.float32 [1, 1, 288, 288] min=-23.9339 max=10.6375   presence_logit=None
[04:39]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.4553 max=12.7722   pred_boxes=torch.float32 [1, 200, 4] min=0.0141 max=0.9894
[04:39]   [ComfyUI] [MEM] After apply prompt obj=1: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)
[04:39]   [ComfyUI] ComfyUI-Multiband loaded: 15 nodes registered
[04:39]   [ComfyUI] Inference state for e347f3b6 garbage collected
[04:39]   [ComfyUI] BatchToMultiband: Processed 1 images with 3 channels each -> 3 channels
[04:39]   [ComfyUI] [MEM] After reconstruction: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)
[04:39]   [ComfyUI] BatchToMultiband: Processed 7 masks -> 7 channels
[04:39]   [ComfyUI] 
[04:39]   [ComfyUI] BatchToMultiband: Output shape torch.Size([1, 10, 4480, 6720]), channels: ['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']
[04:39]   [ComfyUI]   0%|                                                                                                                                          | 0/30 [00:00<?, ?it/s][MEM] Propagation frame 0/30: VRAM 2.55GB alloc / 3.56GB reserved | RAM: 6.46GB (process), 22.3/47.1GB (system)
[04:39]   [ComfyUI] ResizeMultiband: 4480x6720 -> 600x900
[04:39]   [ComfyUI] PreviewMultibandImage: Batch=1, Channels=10, Names=['img_01_r', 'img_01_g', 'img_01_b', 'mask_01', 'mask_02', 'mask_03', 'mask_04', 'mask_05', 'mask_06', 'mask_07']
[04:39]   [ComfyUI] SaveMultibandImage: Saved to output/multiband.npz
[04:39]   [ComfyUI]   Shape: (1, 10, 600, 900)
[04:39]   [ComfyUI]   Format: npz
[04:39]   [capture-loop] iter=50 t=6.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10
[04:39]   [ComfyUI] 
[04:40]   [ComfyUI]   3%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                             | 1/30 [00:00<00:15,  1.84it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:40]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:40]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:40]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8165 max=5.0384   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:40]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256
[04:40]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256
[04:40]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   memory_text=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256
[04:40]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   presence=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374
[04:40]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8095 max=5.1655   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0092 max=0.9864   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374
[04:40]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   prompt=torch.float32 [33, 1, 256] min=-6.3064 max=10.2256   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784
[04:40]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7331 max=0.8784   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0936 max=-10.7374
[04:40]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:40]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876
[04:40]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8095 max=5.1655   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5523 max=11.4215
[04:40]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.2232 max=10.7379   presence_logit=None
[04:40]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.2418 max=10.4332   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9876
[04:40]   Frame 4 saved (frame_003.jpg, t=7.1s)
[04:40]   [capture-periodic] freeze=3ms shot=205ms unfreeze=7ms saved=True
[04:40]   [ComfyUI] 
[04:40]   [ComfyUI]   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                         | 2/30 [00:01<00:15,  1.78it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:40]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:40]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:40]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7366 max=5.0431   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:40]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271
[04:40]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271
[04:40]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:40]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:40]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   memory_text=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271
[04:41]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965
[04:41]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7335 max=4.6877   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0087 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965
[04:41]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   prompt=torch.float32 [33, 1, 256] min=-6.2750 max=10.1271   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705
[04:41]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5828 max=0.7705   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6183 max=-11.2965
[04:41]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:41]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870
[04:41]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7335 max=4.6877   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8444 max=11.1726
[04:41]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0716 max=10.7615   presence_logit=None
[04:41]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.6284 max=12.2672   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9870
[04:41]   [ComfyUI] 
[04:41]   [ComfyUI]  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                     | 3/30 [00:01<00:14,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:41]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:41]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:41]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9970 max=4.7377   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:41]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408
[04:41]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408
[04:41]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   memory_text=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408
[04:41]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161
[04:41]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7188 max=5.2596   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161
[04:41]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   prompt=torch.float32 [33, 1, 256] min=-6.2462 max=10.0408   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082
[04:41]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6055 max=0.8082   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3759 max=-11.0161
[04:41]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:41]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873
[04:41]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7188 max=5.2596   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5331 max=11.5657
[04:41]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7566 max=10.1368   presence_logit=None
[04:41]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0065 max=11.4545   pred_boxes=torch.float32 [1, 200, 4] min=0.0103 max=0.9873
[04:41]   [ComfyUI] 
[04:41]   [ComfyUI]  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                | 4/30 [00:02<00:13,  1.86it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:41]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:41]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:41]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9172 max=4.5249   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:41]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261
[04:41]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261
[04:41]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:41]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:41]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   memory_text=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261
[04:42]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339
[04:42]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4737 max=4.6809   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0051 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339
[04:42]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   prompt=torch.float32 [33, 1, 256] min=-6.2867 max=10.1261   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:42]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933
[04:42]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6423 max=0.7933   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4885 max=-11.1339
[04:42]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:42]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865
[04:42]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4737 max=4.6809   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6636 max=11.4208
[04:42]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.8258 max=10.6992   presence_logit=None
[04:42]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.9952 max=13.6207   pred_boxes=torch.float32 [1, 200, 4] min=0.0053 max=0.9865
[04:42]   [ComfyUI] 
[04:42]   [ComfyUI]  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                            | 5/30 [00:02<00:13,  1.90it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:42]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:42]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:42]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:42]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:42]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:42]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9882 max=4.6801   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:42]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:42]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:42]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498
[04:42]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498
[04:42]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:42]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:42]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:42]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   memory_text=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498
[04:42]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   presence=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733
[04:42]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6865 max=4.8545   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0100 max=0.9871   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733
[04:42]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   prompt=torch.float32 [33, 1, 256] min=-6.2752 max=10.1498   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:42]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346
[04:42]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6342 max=0.7346   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7257 max=-11.3733
[04:42]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:42]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883
[04:42]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6865 max=4.8545   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.7035 max=11.7657
[04:42]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4226 max=10.4522   presence_logit=None
[04:42]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-74.8641 max=11.6359   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9883
[04:42]   [ComfyUI] 
[04:43]   Frame 5 saved (frame_004.jpg, t=9.7s)
[04:43]   [capture-periodic] freeze=11ms shot=220ms unfreeze=4ms saved=True
[04:43]   [ComfyUI]  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                        | 6/30 [00:03<00:15,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:43]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:43]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:43]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8051 max=4.6992   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:43]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958
[04:43]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958
[04:43]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   memory_text=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958
[04:43]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   presence=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781
[04:43]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7308 max=4.9474   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0115 max=0.9892   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781
[04:43]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   prompt=torch.float32 [33, 1, 256] min=-6.3044 max=10.1958   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639
[04:43]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.5997 max=0.8639   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2195 max=-10.8781
[04:43]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:43]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901
[04:43]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7308 max=4.9474   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3077 max=11.0681
[04:43]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   semantic_seg=torch.float32 [1, 1, 288, 288] min=-19.0111 max=10.4409   presence_logit=None
[04:43]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-79.2889 max=11.1597   pred_boxes=torch.float32 [1, 200, 4] min=0.0144 max=0.9901
[04:43]   [ComfyUI] 
[04:43]   [ComfyUI]  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                   | 7/30 [00:04<00:14,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:43]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:43]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:43]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0940 max=4.6755   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:43]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202
[04:43]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202
[04:43]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:43]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:43]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   memory_text=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202
[04:44]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   presence=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644
[04:44]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7743 max=4.8814   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0038 max=0.9886   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644
[04:44]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   prompt=torch.float32 [33, 1, 256] min=-6.3060 max=10.2202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:44]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455
[04:44]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6576 max=0.9455   dec_presence_out=torch.float32 [6, 1, 1] min=-10.5233 max=-10.1644
[04:44]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:44]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896
[04:44]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7743 max=4.8814   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2660 max=11.2370
[04:44]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.0769 max=10.7035   presence_logit=None
[04:44]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-88.6950 max=12.0901   pred_boxes=torch.float32 [1, 200, 4] min=0.0055 max=0.9896
[04:44]   [ComfyUI] 
[04:44]   [ComfyUI]  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                               | 8/30 [00:04<00:13,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:44]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:44]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:44]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0808 max=5.0691   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:44]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:44]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:44]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230
[04:44]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230
[04:44]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:44]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   memory_text=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230
[04:44]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   presence=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378
[04:44]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8517 max=5.1232   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0119 max=0.9877   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378
[04:44]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   prompt=torch.float32 [33, 1, 256] min=-6.3052 max=10.2230   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:44]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713
[04:44]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4261 max=0.8713   dec_presence_out=torch.float32 [6, 1, 1] min=-10.8606 max=-10.5378
[04:44]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:44]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887
[04:44]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8517 max=5.1232   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2509 max=11.4695
[04:44]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0573 max=10.9168   presence_logit=None
[04:44]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-87.4563 max=12.6591   pred_boxes=torch.float32 [1, 200, 4] min=0.0157 max=0.9887
[04:44]   [ComfyUI] 
[04:44]   [ComfyUI]  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                           | 9/30 [00:05<00:12,  1.70it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:44]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:44]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:44]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:45]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1184 max=4.6493   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:45]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894
[04:45]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894
[04:45]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:45]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:45]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   memory_text=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894
[04:45]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   presence=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720
[04:45]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8417 max=4.7029   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0093 max=0.9862   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720
[04:45]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   prompt=torch.float32 [33, 1, 256] min=-6.3071 max=10.1894   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332
[04:45]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-4.9770 max=0.7332   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1931 max=-10.8720
[04:45]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:45]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873
[04:45]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8417 max=4.7029   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8616 max=11.3321
[04:45]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.3237 max=11.7085   presence_logit=None
[04:45]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-89.5923 max=13.7972   pred_boxes=torch.float32 [1, 200, 4] min=0.0123 max=0.9873
[04:45]   [ComfyUI] 
[04:45]   [ComfyUI]  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                      | 10/30 [00:05<00:11,  1.75it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:45]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:45]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:45]   Frame 6 saved (frame_005.jpg, t=12.0s)
[04:45]   [capture-periodic] freeze=3ms shot=158ms unfreeze=8ms saved=True
[04:45]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:45]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:45]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:45]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7034 max=5.0664   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:45]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975
[04:45]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975
[04:45]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:45]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:45]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   memory_text=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975
[04:45]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   presence=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884
[04:45]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.3662 max=4.9779   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0074 max=0.9868   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884
[04:45]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   prompt=torch.float32 [33, 1, 256] min=-6.3228 max=10.1975   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:45]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785
[04:45]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1057 max=0.6785   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4326 max=-11.0884
[04:45]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:45]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879
[04:45]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.3662 max=4.9779   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1072 max=11.0827
[04:45]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.1813 max=10.7148   presence_logit=None
[04:45]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6417 max=10.2728   pred_boxes=torch.float32 [1, 200, 4] min=0.0088 max=0.9879
[04:45]   [ComfyUI] [MEM] Propagation frame 10/30: VRAM 2.60GB alloc / 3.59GB reserved | RAM: 6.52GB (process), 22.0/47.1GB (system)
[04:46]   [ComfyUI] 
[04:46]   [ComfyUI]  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                 | 11/30 [00:06<00:13,  1.41it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:46]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:46]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:46]   [capture-loop] iter=100 t=13.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4
[04:46]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7469 max=5.4390   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:46]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:46]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:46]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312
[04:46]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312
[04:46]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:46]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   memory_text=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312
[04:46]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807
[04:46]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7808 max=4.8949   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0064 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807
[04:46]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   prompt=torch.float32 [33, 1, 256] min=-6.3189 max=10.1312   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:46]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918
[04:46]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1589 max=0.6918   dec_presence_out=torch.float32 [6, 1, 1] min=-11.1000 max=-10.7807
[04:46]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:46]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874
[04:46]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7808 max=4.8949   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2484 max=11.0916
[04:46]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.2139 max=12.2748   presence_logit=None
[04:46]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.5247 max=12.0786   pred_boxes=torch.float32 [1, 200, 4] min=0.0117 max=0.9874
[04:46]   [ComfyUI] 
[04:46]   [ComfyUI]  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                             | 12/30 [00:07<00:11,  1.52it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:46]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:46]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:46]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:47]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8360 max=5.0745   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:47]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245
[04:47]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245
[04:47]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   memory_text=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245
[04:47]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   presence=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571
[04:47]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.6294 max=4.9646   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0044 max=0.9856   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571
[04:47]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   prompt=torch.float32 [33, 1, 256] min=-6.3222 max=10.1245   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042
[04:47]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2430 max=0.6042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.4464 max=-11.1571
[04:47]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:47]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869
[04:47]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.6294 max=4.9646   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5540 max=11.1018
[04:47]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.9154 max=10.2142   presence_logit=None
[04:47]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.1083 max=12.0267   pred_boxes=torch.float32 [1, 200, 4] min=0.0069 max=0.9869
[04:47]   [ComfyUI] 
[04:47]   [ComfyUI]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                         | 13/30 [00:07<00:10,  1.61it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:47]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:47]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:47]   Frame 7 saved (frame_006.jpg, t=14.3s)
[04:47]   [capture-periodic] freeze=5ms shot=206ms unfreeze=4ms saved=True
[04:47]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7564 max=4.8339   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:47]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889
[04:47]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889
[04:47]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   memory_text=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889
[04:47]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798
[04:47]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8459 max=4.9626   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798
[04:47]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   prompt=torch.float32 [33, 1, 256] min=-6.3262 max=10.1889   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:47]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233
[04:47]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0775 max=0.6233   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3617 max=-11.0798
[04:47]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:47]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876
[04:47]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8459 max=4.9626   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.1064 max=11.4282
[04:47]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   semantic_seg=torch.float32 [1, 1, 288, 288] min=-24.7936 max=10.9234   presence_logit=None
[04:47]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.6531 max=14.0017   pred_boxes=torch.float32 [1, 200, 4] min=0.0160 max=0.9876
[04:47]   [ComfyUI] 
[04:47]   [ComfyUI]  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                    | 14/30 [00:08<00:09,  1.66it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:47]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:48]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:48]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:48]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8223 max=4.5463   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:48]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740
[04:48]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740
[04:48]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   memory_text=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740
[04:48]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   presence=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144
[04:48]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1939 max=4.8268   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0055 max=0.9884   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144
[04:48]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   prompt=torch.float32 [33, 1, 256] min=-6.3372 max=10.2740   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728
[04:48]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1844 max=0.6728   dec_presence_out=torch.float32 [6, 1, 1] min=-11.2677 max=-11.0144
[04:48]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:48]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895
[04:48]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1939 max=4.8268   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8309 max=11.0972
[04:48]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   semantic_seg=torch.float32 [1, 1, 288, 288] min=-25.5326 max=10.3234   presence_logit=None
[04:48]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-86.0835 max=15.9998   pred_boxes=torch.float32 [1, 200, 4] min=0.0063 max=0.9895
[04:48]   [ComfyUI] 
[04:48]   [ComfyUI]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                | 15/30 [00:08<00:08,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:48]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:48]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:48]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3420 max=4.7108   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:48]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379
[04:48]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379
[04:48]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   memory_text=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379
[04:48]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   presence=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744
[04:48]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.4315 max=4.8171   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0060 max=0.9859   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744
[04:48]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   prompt=torch.float32 [33, 1, 256] min=-6.3289 max=10.1379   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:48]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497
[04:48]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1249 max=0.5497   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8136 max=-11.5744
[04:48]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:48]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871
[04:48]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.4315 max=4.8171   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.9614 max=11.4070
[04:48]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   semantic_seg=torch.float32 [1, 1, 288, 288] min=-17.7006 max=10.0699   presence_logit=None
[04:48]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-78.8721 max=12.5701   pred_boxes=torch.float32 [1, 200, 4] min=0.0081 max=0.9871
[04:48]   [ComfyUI] 
[04:48]   [ComfyUI]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                            | 16/30 [00:09<00:07,  1.77it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:48]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:49]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:49]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:49]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.3629 max=4.5068   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:49]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693
[04:49]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693
[04:49]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   memory_text=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693
[04:49]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   presence=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474
[04:49]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0847 max=5.0309   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0061 max=0.9855   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474
[04:49]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   prompt=torch.float32 [33, 1, 256] min=-6.3194 max=10.1693   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069
[04:49]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.0591 max=0.5069   dec_presence_out=torch.float32 [6, 1, 1] min=-11.6380 max=-11.3474
[04:49]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:49]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866
[04:49]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0847 max=5.0309   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-21.0183 max=10.9059
[04:49]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.4517 max=10.0732   presence_logit=None
[04:49]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1579 max=12.6812   pred_boxes=torch.float32 [1, 200, 4] min=0.0101 max=0.9866
[04:49]   [ComfyUI] 
[04:49]   [ComfyUI]  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                        | 17/30 [00:10<00:07,  1.80it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:49]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:49]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:49]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.2898 max=4.5872   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:49]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202
[04:49]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202
[04:49]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:49]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   memory_text=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202
[04:49]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   presence=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447
[04:49]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8708 max=4.9522   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0070 max=0.9833   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447
[04:49]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   prompt=torch.float32 [33, 1, 256] min=-6.2453 max=9.9202   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:49]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044
[04:49]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2448 max=0.4044   dec_presence_out=torch.float32 [6, 1, 1] min=-12.7014 max=-12.1447
[04:49]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9078
[04:49]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847
[04:49]   Frame 8 saved (frame_007.jpg, t=16.6s)
[04:49]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8708 max=4.9522   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.8858 max=10.7356
[04:49]   [capture-periodic] freeze=3ms shot=162ms unfreeze=7ms saved=True
[04:49]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4679 max=9.3085   presence_logit=None
[04:49]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-75.7799 max=14.0727   pred_boxes=torch.float32 [1, 200, 4] min=0.0094 max=0.9847
[04:50]   [ComfyUI] 
[04:50]   [ComfyUI]  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 18/30 [00:10<00:06,  1.81it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:50]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:50]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:50]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.4744 max=5.0840   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:50]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742
[04:50]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742
[04:50]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   memory_text=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742
[04:50]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   presence=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925
[04:50]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1408 max=5.0447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0056 max=0.9865   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925
[04:50]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   prompt=torch.float32 [33, 1, 256] min=-6.3293 max=10.1742   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149
[04:50]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.4118 max=0.6149   dec_presence_out=torch.float32 [6, 1, 1] min=-11.7655 max=-11.4925
[04:50]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:50]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876
[04:50]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1408 max=5.0447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6426 max=11.8421
[04:50]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.5293 max=10.4309   presence_logit=None
[04:50]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7311 max=12.2612   pred_boxes=torch.float32 [1, 200, 4] min=0.0067 max=0.9876
[04:50]   [ComfyUI] 
[04:50]   [ComfyUI]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                               | 19/30 [00:11<00:05,  1.83it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:50]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:50]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:50]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9539 max=4.8733   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:50]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269
[04:50]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269
[04:50]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:50]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:50]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   memory_text=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269
[04:50]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   presence=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809
[04:51]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7461 max=5.0539   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0045 max=0.9866   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809
[04:51]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   prompt=torch.float32 [33, 1, 256] min=-6.2979 max=10.1269   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:51]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531
[04:51]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.1513 max=0.5531   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8651 max=-11.5809
[04:51]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:51]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878
[04:51]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7461 max=5.0539   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.6926 max=11.4938
[04:51]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.1786 max=9.2699   presence_logit=None
[04:51]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-83.3065 max=11.6271   pred_boxes=torch.float32 [1, 200, 4] min=0.0074 max=0.9878
[04:51]   [ComfyUI] 
[04:51]   [ComfyUI]  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                           | 20/30 [00:11<00:05,  1.85it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:51]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:51]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:51]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:51]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:51]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:51]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.1614 max=4.8866   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:51]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:51]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:51]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877
[04:51]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877
[04:51]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:51]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:51]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:51]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   memory_text=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877
[04:51]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   presence=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115
[04:51]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1415 max=5.0314   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0082 max=0.9861   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115
[04:51]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   prompt=torch.float32 [33, 1, 256] min=-6.3048 max=10.1877   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:51]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965
[04:51]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2072 max=0.5965   dec_presence_out=torch.float32 [6, 1, 1] min=-11.8786 max=-11.6115
[04:51]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:51]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872
[04:51]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1415 max=5.0314   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4347 max=11.4510
[04:51]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   semantic_seg=torch.float32 [1, 1, 288, 288] min=-11.6523 max=8.9172   presence_logit=None
[04:51]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-84.5353 max=10.7031   pred_boxes=torch.float32 [1, 200, 4] min=0.0114 max=0.9872
[04:51]   [ComfyUI] [MEM] Propagation frame 20/30: VRAM 2.61GB alloc / 3.66GB reserved | RAM: 6.58GB (process), 22.1/47.1GB (system)
[04:52]   [ComfyUI] 
[04:52]   [ComfyUI]  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                      | 21/30 [00:12<00:06,  1.44it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:52]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:52]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:52]   Frame 9 saved (frame_008.jpg, t=19.0s)
[04:52]   [capture-periodic] freeze=7ms shot=177ms unfreeze=7ms saved=True
[04:52]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9470 max=4.9073   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:52]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:52]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:52]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224
[04:52]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224
[04:52]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:52]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   memory_text=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224
[04:52]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   presence=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508
[04:52]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.1429 max=5.2999   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0084 max=0.9851   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508
[04:52]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   prompt=torch.float32 [33, 1, 256] min=-6.2980 max=10.1224   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:52]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597
[04:52]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.2841 max=0.6597   dec_presence_out=torch.float32 [6, 1, 1] min=-11.9478 max=-11.6508
[04:52]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:52]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864
[04:52]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.1429 max=5.2999   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.5168 max=11.3998
[04:52]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.4222 max=9.8810   presence_logit=None
[04:52]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9078   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7838 max=11.3079   pred_boxes=torch.float32 [1, 200, 4] min=0.0147 max=0.9864
[04:52]   [capture-loop] iter=150 t=19.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=6
[04:52]   [ComfyUI] 
[04:52]   [ComfyUI]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 22/30 [00:13<00:05,  1.55it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:52]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:52]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:52]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:52]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8092 max=4.9807   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:53]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805
[04:53]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805
[04:53]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   memory_text=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805
[04:53]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   presence=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013
[04:53]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.9503 max=5.3718   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0102 max=0.9874   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013
[04:53]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   prompt=torch.float32 [33, 1, 256] min=-6.3047 max=10.1805   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242
[04:53]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8375 max=0.8242   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9512 max=-10.6013
[04:53]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:53]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883
[04:53]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.9503 max=5.3718   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1158 max=11.4602
[04:53]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.0793 max=10.7325   presence_logit=None
[04:53]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-85.9474 max=11.1399   pred_boxes=torch.float32 [1, 200, 4] min=0.0152 max=0.9883
[04:53]   [ComfyUI] 
[04:53]   [ComfyUI]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 23/30 [00:13<00:04,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:53]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:53]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:53]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.8678 max=5.1199   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:53]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276
[04:53]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276
[04:53]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   memory_text=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276
[04:53]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   presence=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320
[04:53]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7413 max=5.3447   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0104 max=0.9876   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320
[04:53]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   prompt=torch.float32 [33, 1, 256] min=-6.3105 max=10.2276   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:53]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779
[04:53]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8222 max=0.7779   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3652 max=-11.0320
[04:53]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:53]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886
[04:53]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7413 max=5.3447   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.3093 max=11.5599
[04:53]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   semantic_seg=torch.float32 [1, 1, 288, 288] min=-14.4459 max=10.5971   presence_logit=None
[04:53]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.8619 max=11.3417   pred_boxes=torch.float32 [1, 200, 4] min=0.0142 max=0.9886
[04:53]   [ComfyUI] 
[04:53]   [ComfyUI]  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 24/30 [00:14<00:03,  1.63it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:53]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:53]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:53]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:54]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.7979 max=4.8057   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:54]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576
[04:54]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576
[04:54]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   memory_text=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576
[04:54]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253
[04:54]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.8950 max=5.2919   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0079 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253
[04:54]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   prompt=torch.float32 [33, 1, 256] min=-6.3077 max=10.1576   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782
[04:54]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7611 max=0.7782   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5801 max=-11.2253
[04:54]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:54]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882
[04:54]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.8950 max=5.2919   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2131 max=10.6234
[04:54]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1415 max=10.6327   presence_logit=None
[04:54]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-76.0209 max=11.8179   pred_boxes=torch.float32 [1, 200, 4] min=0.0132 max=0.9882
[04:54]   [ComfyUI] 
[04:54]   [ComfyUI]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 25/30 [00:14<00:03,  1.62it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:54]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:54]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:54]   Frame 10 saved (frame_009.jpg, t=21.3s)
[04:54]   [capture-periodic] freeze=48ms shot=212ms unfreeze=9ms saved=True
[04:54]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9362 max=5.0820   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:54]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803
[04:54]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803
[04:54]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:54]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   memory_text=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803
[04:54]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   presence=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759
[04:54]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0783 max=4.8924   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0073 max=0.9870   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759
[04:54]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   prompt=torch.float32 [33, 1, 256] min=-6.2942 max=10.1803   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:54]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885
[04:54]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.6338 max=0.6885   dec_presence_out=torch.float32 [6, 1, 1] min=-11.5976 max=-11.2759
[04:54]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:54]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882
[04:54]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0783 max=4.8924   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4865 max=11.0800
[04:54]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   semantic_seg=torch.float32 [1, 1, 288, 288] min=-16.1185 max=12.2840   presence_logit=None
[04:54]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-72.6743 max=10.3929   pred_boxes=torch.float32 [1, 200, 4] min=0.0111 max=0.9882
[04:55]   [ComfyUI] 
[04:55]   [ComfyUI]  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 26/30 [00:15<00:02,  1.64it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:55]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:55]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:55]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-5.0467 max=4.8336   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:55]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874
[04:55]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874
[04:55]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   memory_text=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874
[04:55]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   presence=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131
[04:55]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.0275 max=4.8319   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0109 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131
[04:55]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   prompt=torch.float32 [33, 1, 256] min=-6.3082 max=10.1874   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042
[04:55]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.7818 max=0.7042   dec_presence_out=torch.float32 [6, 1, 1] min=-11.0971 max=-10.8131
[04:55]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:55]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879
[04:55]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.0275 max=4.8319   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.4057 max=10.5591
[04:55]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   semantic_seg=torch.float32 [1, 1, 288, 288] min=-12.8003 max=9.9163   presence_logit=None
[04:55]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.1951 max=10.7547   pred_boxes=torch.float32 [1, 200, 4] min=0.0156 max=0.9879
[04:55]   [ComfyUI] 
[04:55]   [ComfyUI]  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 27/30 [00:16<00:01,  1.69it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:55]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:55]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:55]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9010 max=4.8039   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:55]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521
[04:55]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521
[04:55]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:55]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:55]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   memory_text=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521
[04:56]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   presence=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829
[04:56]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-4.7048 max=4.7738   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0101 max=0.9867   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829
[04:56]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   prompt=torch.float32 [33, 1, 256] min=-6.3278 max=10.2521   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:56]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005
[04:56]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-6.0003 max=0.8005   dec_presence_out=torch.float32 [6, 1, 1] min=-10.9615 max=-10.5829
[04:56]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:56]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879
[04:56]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-4.7048 max=4.7738   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.1360 max=11.1395
[04:56]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   semantic_seg=torch.float32 [1, 1, 288, 288] min=-15.1473 max=10.9938   presence_logit=None
[04:56]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-82.0464 max=11.3714   pred_boxes=torch.float32 [1, 200, 4] min=0.0129 max=0.9879
[04:56]   [ComfyUI] 
[04:56]   [ComfyUI]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 28/30 [00:16<00:01,  1.73it/s]Backbone.forward_image IN:   samples=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:56]   [ComfyUI] FPN_Neck.forward IN:   input=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:56]   [ComfyUI] ViT.forward IN:   x=torch.float32 [1, 3, 1008, 1008] min=-1.0000 max=1.0000
[04:56]   [ComfyUI] ViT.forward OUT:   features=[torch.float32 [1, 1024, 72, 72]]
[04:56]   [ComfyUI] FPN_Neck.forward after trunk:   trunk_out=[torch.float32 [1, 1024, 72, 72]]
[04:56]   [ComfyUI] FPN_Neck.forward OUT:   sam3_out=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]   sam3_pos=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72], torch.float32 [1, 256, 36, 36]]
[04:56]   [ComfyUI] Backbone.forward_image OUT:   vision_features=torch.float32 [1, 256, 72, 72] min=-4.9888 max=4.9197   backbone_fpn=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]
[04:56]   [ComfyUI] forward_grounding: after _encode_prompt:   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:56]   [ComfyUI] _run_encoder inputs:   img_feats=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:56]   [ComfyUI] Encoder.forward IN:   src=[torch.float32 [5184, 1, 256]]   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994
[04:56]   [ComfyUI] Encoder.forward OUT:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994
[04:56]   [ComfyUI] _run_encoder output:   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:56]   [ComfyUI] forward_grounding: after _run_encoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000
[04:56]   [ComfyUI] _run_decoder inputs:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pos_embed=torch.float32 [5184, 1, 256] min=-1.0000 max=1.0000   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:56]   [ComfyUI] Decoder.forward IN:   tgt=torch.float32 [200, 1, 256] min=-0.6744 max=0.5923   memory=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   memory_text=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994
[04:56]   [ComfyUI] Decoder.forward OUT:   output=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   ref_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   presence=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020
[04:56]   [ComfyUI] _run_decoder output:   hs=torch.float32 [6, 200, 1, 256] min=-5.6428 max=4.8676   reference_boxes=torch.float32 [6, 200, 1, 4] min=0.0062 max=0.9863   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020
[04:56]   [ComfyUI] _update_scores_and_boxes:   hs=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   prompt=torch.float32 [33, 1, 256] min=-6.3281 max=10.1994   prompt_mask=torch.bool [1, 33] min=0.0000 max=1.0000
[04:56]   [ComfyUI] _update_scores: outputs_class:   outputs_class=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284
[04:56]   [ComfyUI] _update_scores: before joint_box_scores:   outputs_class_pre=torch.float32 [6, 1, 200, 1] min=-5.8563 max=0.8284   dec_presence_out=torch.float32 [6, 1, 1] min=-11.3351 max=-11.0020
[04:56]   [ComfyUI] _update_scores: after joint_box_scores:   outputs_class_post=torch.float32 [6, 1, 200, 1] min=-6.9078 max=-6.9077
[04:56]   [ComfyUI] forward_grounding: after _run_decoder:   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875
[04:56]   [ComfyUI] SegHead.forward IN:   backbone_feats=[torch.float32 [1, 256, 288, 288], torch.float32 [1, 256, 144, 144], torch.float32 [1, 256, 72, 72]]   obj_queries=torch.float32 [6, 1, 200, 256] min=-5.6428 max=4.8676   encoder_hidden_states=torch.float32 [5184, 1, 256] min=-20.2774 max=10.7190
[04:56]   [ComfyUI] SegHead.forward OUT:   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   semantic_seg=torch.float32 [1, 1, 288, 288] min=-13.7399 max=10.5600   presence_logit=None
[04:56]   [ComfyUI] forward_grounding: after _run_segmentation_heads:   pred_logits=torch.float32 [1, 200, 1] min=-6.9078 max=-6.9077   pred_masks=torch.float32 [1, 200, 288, 288] min=-77.7246 max=12.8041   pred_boxes=torch.float32 [1, 200, 4] min=0.0061 max=0.9875
[04:56]   [ComfyUI] 
[04:56]   [ComfyUI]  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 29/30 [00:17<00:00,  1.72it/s]
[04:56]   [ComfyUI] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:17<00:00,  1.73it/s]
[04:56]   [ComfyUI] [MEM] After propagation loop: VRAM 2.41GB alloc / 3.66GB reserved | RAM: 6.66GB (process), 22.4/47.1GB (system)
[04:56]   [ComfyUI] Propagation complete: 30 frames processed
[04:56]   [ComfyUI] Frames with scores: 30
[04:56]   Frame 11 saved (frame_010.jpg, t=23.7s)
[04:56]   [capture-periodic] freeze=3ms shot=141ms unfreeze=4ms saved=True
[04:57]   [ComfyUI] Video Output CACHE MISS - streaming extraction for session=e347f3b6
[04:57]   [ComfyUI] [MEM] Before extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 6.66GB (process), 22.3/47.1GB (system)
[04:57]   [ComfyUI] Streaming 30 frames to disk: /tmp/sam3_e347f3b6_8uc25nxo/mmap_output
[04:58]   [capture-loop] iter=200 t=25.6s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=10
[04:59]   Frame 12 saved (frame_011.jpg, t=26.0s)
[04:59]   [capture-periodic] freeze=3ms shot=146ms unfreeze=6ms saved=True
[05:01]   Frame 13 saved (frame_012.jpg, t=28.2s)
[05:01]   [capture-periodic] freeze=3ms shot=161ms unfreeze=7ms saved=True
[05:03]   Frame 14 saved (frame_013.jpg, t=30.5s)
[05:03]   [capture-periodic] freeze=6ms shot=158ms unfreeze=6ms saved=True
[05:04]   [capture-loop] iter=250 t=31.7s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4
[05:06]   Frame 15 saved (frame_014.jpg, t=32.8s)
[05:06]   [capture-periodic] freeze=3ms shot=189ms unfreeze=5ms saved=True
[05:08]   Frame 16 saved (frame_015.jpg, t=35.2s)
[05:08]   [capture-periodic] freeze=3ms shot=162ms unfreeze=4ms saved=True
[05:10]   Frame 17 saved (frame_016.jpg, t=37.6s)
[05:11]   [capture-periodic] freeze=4ms shot=198ms unfreeze=5ms saved=True
[05:11]   [capture-loop] iter=300 t=38.3s state={'complete': False, 'error': None, 'executedCount': 1, 'wsState': 1} eval_ms=4
[05:11]   [ComfyUI] Output: 30 masks, shape torch.Size([30, 544, 960])
[05:11]   [ComfyUI] Objects tracked: 1, plot_all_masks: True
[05:11]   [ComfyUI] [MEM] After extract: VRAM 2.41GB alloc / 2.88GB reserved | RAM: 7.12GB (process), 22.4/47.1GB (system)
[05:12]   Node executed (2 total), capturing...
[05:13]   [ComfyUI] Prompt executed in 39.94 seconds
[05:13]   Frame 18 saved (frame_017.jpg, t=39.9s)
[05:13]   [capture-node] freeze=5ms shot=253ms unfreeze=14ms saved=True
[05:13]   Node executed (3 total), capturing...
[05:13]   Frame 19 saved (frame_018.jpg, t=40.5s)
[05:13]   [capture-node] freeze=4ms shot=319ms unfreeze=0ms saved=True
[05:13]   Execution complete (t=40.5s)
[05:13]   Captured 19 unique frames over 40.89s
[05:13]   [debug] iframes: 0
[05:14]   [timing] trigger_3d_previews: 0.0s
[05:17]   Saved high-quality screenshot: video_point_prompt_executed.png
[05:17]   [timing] final_screenshot: 1.6s
[05:17] 
[VRAM] Peak across all workflows: 4096 MiB / 49140 MiB (8.3%)
[05:17] Results saved to /home/shadeform/logs/SAM3-0057/dev/linux-gpu/results.json
[05:17] Model report: 3 files, 3.2 GB -> /home/shadeform/logs/SAM3-0057/dev/linux-gpu/models.json
[05:17] Saved: /home/shadeform/logs/SAM3-0057/dev/linux-gpu/index.html
[05:17] [EXECUTION] PASSED
[05:17] 
linux: PASSED
[05:17] Stopping ComfyUI server...
